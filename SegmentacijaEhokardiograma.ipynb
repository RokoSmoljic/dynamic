{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SegmentacijaEhokardiograma.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bzY_2uZHU5s3",
        "zTmG-p_Rz8zy",
        "oY7Z5-3aWqS5",
        "oYByKY-t0AmZ",
        "7EmWQyFaz_qz"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RokoSmoljic/dynamic/blob/master/SegmentacijaEhokardiograma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Segmentacija Ehokardiograma\n",
        "## Računska inteligencija - seminarski rad \n"
      ],
      "metadata": {
        "id": "9ZYm-Fu_Ciqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Dataset \n",
        "---\n",
        "Naziv: EchoNet-Dynamic\n",
        "\n",
        "Dataset link: [https://echonet.github.io/dynamic/](https://echonet.github.io/dynamic/)\n",
        "\n",
        "Sadržaj: 10,030 ehokardiograma snimljenih između 2016. i 2018. u sveučilišnoj bolnici sveučilišta Stanford. Snimke su rezolucije 112 x 112 piksela.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W_z6KeCjA6mc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyHYinzMANNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f609e453-a66f-4059-b435-0ecfb0dfb0e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "#@title Default title text\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/EchoNet-Dynamic'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiekYjyrj9kZ",
        "outputId": "8ebec58c-b318-4684-ce3a-c7d1e00a0b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FileList.csv  Videos  VolumeTracings.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upute\n",
        "### Import python modula\n",
        "**All the cells in the notebook have the same access to all the variables you generated within a session. You have to import the libraries you use only once, and you don't have to import anything else. You can just run your cells linearly. The variables/functions/classes you use must just be defined before you use them, just like a regular python script.**\n",
        "### Import python skripti kao modula tamo di triba\n",
        "Najbolje koristi princip iz ovog [videa](https://www.youtube.com/watch?v=YP6APKLRf58) da ih ucitamo na luksicev google drive i importamo otud ko trenutno u kodu"
      ],
      "metadata": {
        "id": "iFZ5AG24HVPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r '/content/drive/My Drive/dynamic' dynamic"
      ],
      "metadata": {
        "id": "551fsfUQk2uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install '/content/dynamic' \n"
      ],
      "metadata": {
        "id": "boaAfq7QMDwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7eda343-4eaf-4164-c28c-6398e05bbd4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./dynamic\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from echonet==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from echonet==1.0.0) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from echonet==1.0.0) (1.3.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from echonet==1.0.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from echonet==1.0.0) (0.12.0+cu113)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from echonet==1.0.0) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from echonet==1.0.0) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from echonet==1.0.0) (4.64.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from echonet==1.0.0) (0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->echonet==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->echonet==1.0.0) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->echonet==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->echonet==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->echonet==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->echonet==1.0.0) (3.2.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->echonet==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->echonet==1.0.0) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->echonet==1.0.0) (2.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->echonet==1.0.0) (2021.11.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->echonet==1.0.0) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->echonet==1.0.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->echonet==1.0.0) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->echonet==1.0.0) (4.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->echonet==1.0.0) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->echonet==1.0.0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->echonet==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->echonet==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->echonet==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->echonet==1.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->echonet==1.0.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->echonet==1.0.0) (1.24.3)\n",
            "Building wheels for collected packages: echonet\n",
            "  Building wheel for echonet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for echonet: filename=echonet-1.0.0-py3-none-any.whl size=21180 sha256=c699d5f3c72afbe2820a7581613a8cf937b3b73424873739824fae248663759b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m4796bby/wheels/ff/e9/32/ccda2a834131021715637595ea02fb68326ecdc53018cb41b6\n",
            "Successfully built echonet\n",
            "Installing collected packages: echonet\n",
            "Successfully installed echonet-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "FJ-y5HK_jRZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import echonet\n",
        "echonet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAw2f3I8mFg4",
        "outputId": "0192ea38-eaaa-44a0-f019-109d50f7c7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'echonet' from '/usr/local/lib/python3.7/dist-packages/echonet/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hENSbhWs03o3",
        "outputId": "8629a337-a036-4838-98f3-f978cc7031c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun 19 16:34:22 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r ./output.zip ./output/"
      ],
      "metadata": {
        "id": "C5u6tJJx9bhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echonet segmentation --model_name=\"deeplabv3_resnet50\" --num_epochs=200 --output=\"output/training_size/segmentation/256\" --num_train_patients=256 --run_test --save_video --data_dir='/content/drive/My Drive/EchoNet-Dynamic'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS5roiSU0foS",
        "outputId": "654f9396-926e-4519-ad8a-d012979d7c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 16/16 [00:59<00:00,  3.69s/it]\n",
            "Epoch #0\n",
            "100% 12/12 [00:20<00:00,  1.71s/it, 0.5867 (0.2685) / 0.3128 0.1435, 0.0375, 0.0380]\n",
            "100% 65/65 [01:20<00:00,  1.25s/it, 0.6826 (0.3497) / 0.3145 0.1385, 0.0000, 0.0000]\n",
            "Epoch #1\n",
            "100% 12/12 [00:17<00:00,  1.49s/it, 0.2652 (0.2427) / 0.3125 0.1425, 0.0000, 0.0000]\n",
            "100% 65/65 [01:20<00:00,  1.24s/it, 0.3585 (0.3421) / 0.3145 0.1385, 0.0000, 0.0000]\n",
            "Epoch #2\n",
            "100% 12/12 [00:17<00:00,  1.48s/it, 0.2056 (0.1713) / 0.3126 0.1425, 0.3012, 0.3000]\n",
            "100% 65/65 [01:20<00:00,  1.23s/it, 0.2446 (0.2266) / 0.3145 0.1385, 0.4612, 0.5734]\n",
            "Epoch #3\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.1680 (0.1442) / 0.3132 0.1429, 0.5440, 0.6391]\n",
            "100% 65/65 [01:20<00:00,  1.23s/it, 0.2166 (0.1915) / 0.3145 0.1385, 0.4846, 0.6587]\n",
            "Epoch #4\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.1382 (0.1216) / 0.3134 0.1430, 0.6452, 0.6908]\n",
            "100% 65/65 [01:18<00:00,  1.20s/it, 0.1248 (0.1565) / 0.3145 0.1385, 0.6890, 0.7339]\n",
            "Epoch #5\n",
            "100% 12/12 [00:19<00:00,  1.60s/it, 0.1184 (0.1090) / 0.3135 0.1424, 0.6963, 0.7555]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.1275 (0.1519) / 0.3145 0.1385, 0.6308, 0.6703]\n",
            "Epoch #6\n",
            "100% 12/12 [00:17<00:00,  1.42s/it, 0.1080 (0.0938) / 0.3121 0.1422, 0.7158, 0.7675]\n",
            "100% 65/65 [01:19<00:00,  1.23s/it, 0.1049 (0.1101) / 0.3145 0.1385, 0.7332, 0.7842]\n",
            "Epoch #7\n",
            "100% 12/12 [00:17<00:00,  1.42s/it, 0.0973 (0.0896) / 0.3112 0.1416, 0.7409, 0.7992]\n",
            "100% 65/65 [01:19<00:00,  1.23s/it, 0.0966 (0.1044) / 0.3145 0.1385, 0.6768, 0.7882]\n",
            "Epoch #8\n",
            "100% 12/12 [00:17<00:00,  1.42s/it, 0.0894 (0.0800) / 0.3133 0.1435, 0.7668, 0.8170]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0915 (0.0803) / 0.3145 0.1385, 0.7715, 0.7846]\n",
            "Epoch #9\n",
            "100% 12/12 [00:17<00:00,  1.43s/it, 0.0817 (0.0837) / 0.3123 0.1435, 0.7824, 0.8361]\n",
            "100% 65/65 [01:17<00:00,  1.20s/it, 0.0808 (0.0663) / 0.3145 0.1385, 0.8071, 0.8519]\n",
            "Epoch #10\n",
            "100% 12/12 [00:18<00:00,  1.56s/it, 0.0756 (0.0776) / 0.3106 0.1429, 0.7998, 0.8442]\n",
            "100% 65/65 [01:18<00:00,  1.20s/it, 0.0740 (0.1391) / 0.3145 0.1385, 0.8051, 0.8584]\n",
            "Epoch #11\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0741 (0.0673) / 0.3136 0.1424, 0.8065, 0.8557]\n",
            "100% 65/65 [01:20<00:00,  1.24s/it, 0.0705 (0.0580) / 0.3145 0.1385, 0.8142, 0.8651]\n",
            "Epoch #12\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0712 (0.0667) / 0.3141 0.1432, 0.8138, 0.8636]\n",
            "100% 65/65 [01:21<00:00,  1.25s/it, 0.0806 (0.0611) / 0.3145 0.1385, 0.7932, 0.8328]\n",
            "Epoch #13\n",
            "100% 12/12 [00:17<00:00,  1.44s/it, 0.0681 (0.0819) / 0.3122 0.1434, 0.8205, 0.8669]\n",
            "100% 65/65 [01:19<00:00,  1.23s/it, 0.0823 (0.0644) / 0.3145 0.1385, 0.7682, 0.8506]\n",
            "Epoch #14\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0665 (0.0588) / 0.3132 0.1428, 0.8226, 0.8701]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0734 (0.0678) / 0.3145 0.1385, 0.8154, 0.8692]\n",
            "Epoch #15\n",
            "100% 12/12 [00:18<00:00,  1.52s/it, 0.0609 (0.0650) / 0.3120 0.1420, 0.8385, 0.8791]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0670 (0.0487) / 0.3145 0.1385, 0.8369, 0.8773]\n",
            "Epoch #16\n",
            "100% 12/12 [00:17<00:00,  1.44s/it, 0.0578 (0.0617) / 0.3112 0.1426, 0.8436, 0.8892]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0609 (0.0755) / 0.3145 0.1385, 0.8450, 0.8905]\n",
            "Epoch #17\n",
            "100% 12/12 [00:17<00:00,  1.42s/it, 0.0547 (0.0614) / 0.3128 0.1426, 0.8540, 0.8934]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0635 (0.0435) / 0.3145 0.1385, 0.8347, 0.8902]\n",
            "Epoch #18\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0557 (0.0496) / 0.3126 0.1419, 0.8513, 0.8937]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0651 (0.0586) / 0.3145 0.1385, 0.8353, 0.8883]\n",
            "Epoch #19\n",
            "100% 12/12 [00:17<00:00,  1.43s/it, 0.0529 (0.0537) / 0.3123 0.1426, 0.8566, 0.8963]\n",
            "100% 65/65 [01:17<00:00,  1.20s/it, 0.0691 (0.1031) / 0.3145 0.1385, 0.8312, 0.8822]\n",
            "Epoch #20\n",
            "100% 12/12 [00:18<00:00,  1.53s/it, 0.0503 (0.0553) / 0.3129 0.1420, 0.8637, 0.9045]\n",
            "100% 65/65 [01:18<00:00,  1.20s/it, 0.0615 (0.0560) / 0.3145 0.1385, 0.8478, 0.8882]\n",
            "Epoch #21\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0489 (0.0456) / 0.3114 0.1416, 0.8656, 0.9033]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0578 (0.0662) / 0.3145 0.1385, 0.8544, 0.8983]\n",
            "Epoch #22\n",
            "100% 12/12 [00:17<00:00,  1.44s/it, 0.0482 (0.0709) / 0.3128 0.1432, 0.8694, 0.9070]\n",
            "100% 65/65 [01:19<00:00,  1.23s/it, 0.0615 (0.0793) / 0.3145 0.1385, 0.8567, 0.8844]\n",
            "Epoch #23\n",
            "100% 12/12 [00:17<00:00,  1.43s/it, 0.0460 (0.0450) / 0.3131 0.1428, 0.8722, 0.9133]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0575 (0.0562) / 0.3145 0.1385, 0.8575, 0.8956]\n",
            "Epoch #24\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0443 (0.0426) / 0.3141 0.1436, 0.8797, 0.9141]\n",
            "100% 65/65 [01:19<00:00,  1.23s/it, 0.0548 (0.0512) / 0.3145 0.1385, 0.8593, 0.8982]\n",
            "Epoch #25\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0436 (0.0469) / 0.3128 0.1434, 0.8812, 0.9153]\n",
            "100% 65/65 [01:17<00:00,  1.20s/it, 0.0625 (0.0526) / 0.3145 0.1385, 0.8545, 0.8782]\n",
            "Epoch #26\n",
            "100% 12/12 [00:17<00:00,  1.48s/it, 0.0469 (0.0470) / 0.3136 0.1433, 0.8723, 0.9107]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0576 (0.1062) / 0.3145 0.1385, 0.8639, 0.8951]\n",
            "Epoch #27\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0436 (0.0479) / 0.3123 0.1433, 0.8800, 0.9151]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0713 (0.0948) / 0.3145 0.1385, 0.8455, 0.8515]\n",
            "Epoch #28\n",
            "100% 12/12 [00:16<00:00,  1.42s/it, 0.0469 (0.0471) / 0.3155 0.1447, 0.8707, 0.9118]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0575 (0.0671) / 0.3145 0.1385, 0.8655, 0.8946]\n",
            "Epoch #29\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0450 (0.0440) / 0.3122 0.1408, 0.8766, 0.9138]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0561 (0.0535) / 0.3145 0.1385, 0.8579, 0.9008]\n",
            "Epoch #30\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0409 (0.0451) / 0.3145 0.1444, 0.8882, 0.9221]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0626 (0.0498) / 0.3145 0.1385, 0.8489, 0.8982]\n",
            "Epoch #31\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0395 (0.0370) / 0.3129 0.1434, 0.8906, 0.9260]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0573 (0.0650) / 0.3145 0.1385, 0.8593, 0.9032]\n",
            "Epoch #32\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0376 (0.0368) / 0.3123 0.1423, 0.8966, 0.9275]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0608 (0.0630) / 0.3145 0.1385, 0.8530, 0.8993]\n",
            "Epoch #33\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0380 (0.0367) / 0.3125 0.1430, 0.8956, 0.9262]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0747 (0.0652) / 0.3145 0.1385, 0.8243, 0.8878]\n",
            "Epoch #34\n",
            "100% 12/12 [00:17<00:00,  1.42s/it, 0.0381 (0.0407) / 0.3139 0.1422, 0.8951, 0.9282]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0575 (0.0517) / 0.3145 0.1385, 0.8602, 0.8971]\n",
            "Epoch #35\n",
            "100% 12/12 [00:18<00:00,  1.56s/it, 0.0387 (0.0320) / 0.3126 0.1420, 0.8926, 0.9245]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0609 (0.0691) / 0.3145 0.1385, 0.8630, 0.8875]\n",
            "Epoch #36\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0352 (0.0318) / 0.3149 0.1427, 0.9059, 0.9321]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0575 (0.1434) / 0.3145 0.1385, 0.8674, 0.8961]\n",
            "Epoch #37\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0340 (0.0329) / 0.3128 0.1440, 0.9066, 0.9345]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0569 (0.0580) / 0.3145 0.1385, 0.8693, 0.8993]\n",
            "Epoch #38\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0332 (0.0410) / 0.3130 0.1417, 0.9092, 0.9354]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0581 (0.0576) / 0.3145 0.1385, 0.8642, 0.9039]\n",
            "Epoch #39\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0353 (0.0379) / 0.3125 0.1393, 0.9029, 0.9316]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0626 (0.0731) / 0.3145 0.1385, 0.8543, 0.9019]\n",
            "Epoch #40\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0337 (0.0343) / 0.3121 0.1429, 0.9063, 0.9351]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0574 (0.0476) / 0.3145 0.1385, 0.8650, 0.8994]\n",
            "Epoch #41\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0318 (0.0301) / 0.3125 0.1415, 0.9116, 0.9385]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0585 (0.0653) / 0.3145 0.1385, 0.8686, 0.9025]\n",
            "Epoch #42\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0351 (0.0297) / 0.3123 0.1430, 0.9028, 0.9320]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0802 (0.0633) / 0.3145 0.1385, 0.8314, 0.8711]\n",
            "Epoch #43\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0367 (0.0343) / 0.3131 0.1418, 0.9002, 0.9291]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0647 (0.0982) / 0.3145 0.1385, 0.8568, 0.8775]\n",
            "Epoch #44\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0362 (0.0411) / 0.3128 0.1429, 0.8997, 0.9304]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0643 (0.0537) / 0.3145 0.1385, 0.8637, 0.8862]\n",
            "Epoch #45\n",
            "100% 12/12 [00:18<00:00,  1.53s/it, 0.0326 (0.0353) / 0.3120 0.1424, 0.9089, 0.9368]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0595 (0.0450) / 0.3145 0.1385, 0.8731, 0.9001]\n",
            "Epoch #46\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0297 (0.0281) / 0.3129 0.1428, 0.9175, 0.9429]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0597 (0.0390) / 0.3145 0.1385, 0.8714, 0.9003]\n",
            "Epoch #47\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0317 (0.0272) / 0.3126 0.1426, 0.9124, 0.9385]\n",
            "100% 65/65 [01:18<00:00,  1.22s/it, 0.0574 (0.0335) / 0.3145 0.1385, 0.8683, 0.9038]\n",
            "Epoch #48\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0288 (0.0312) / 0.3149 0.1427, 0.9227, 0.9450]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0581 (0.0497) / 0.3145 0.1385, 0.8733, 0.9046]\n",
            "Epoch #49\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0317 (0.0331) / 0.3142 0.1433, 0.9123, 0.9400]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0631 (0.1015) / 0.3145 0.1385, 0.8594, 0.9023]\n",
            "Epoch #50\n",
            "100% 12/12 [00:18<00:00,  1.54s/it, 0.0331 (0.0325) / 0.3136 0.1437, 0.9120, 0.9349]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0669 (0.1591) / 0.3145 0.1385, 0.8498, 0.8981]\n",
            "Epoch #51\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0299 (0.0279) / 0.3142 0.1432, 0.9185, 0.9435]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0566 (0.0552) / 0.3145 0.1385, 0.8704, 0.9061]\n",
            "Epoch #52\n",
            "100% 12/12 [00:17<00:00,  1.42s/it, 0.0288 (0.0305) / 0.3141 0.1442, 0.9202, 0.9455]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0596 (0.0464) / 0.3145 0.1385, 0.8720, 0.9029]\n",
            "Epoch #53\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0273 (0.0291) / 0.3116 0.1425, 0.9248, 0.9479]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0595 (0.0364) / 0.3145 0.1385, 0.8703, 0.9064]\n",
            "Epoch #54\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0286 (0.0295) / 0.3125 0.1423, 0.9213, 0.9446]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0696 (0.0588) / 0.3145 0.1385, 0.8642, 0.8935]\n",
            "Epoch #55\n",
            "100% 12/12 [00:18<00:00,  1.54s/it, 0.0293 (0.0270) / 0.3135 0.1428, 0.9204, 0.9428]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0718 (0.0659) / 0.3145 0.1385, 0.8498, 0.8875]\n",
            "Epoch #56\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0289 (0.0305) / 0.3120 0.1416, 0.9172, 0.9453]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0598 (0.0434) / 0.3145 0.1385, 0.8691, 0.9061]\n",
            "Epoch #57\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0279 (0.0268) / 0.3130 0.1429, 0.9219, 0.9468]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0612 (0.0621) / 0.3145 0.1385, 0.8732, 0.9040]\n",
            "Epoch #58\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0273 (0.0250) / 0.3129 0.1424, 0.9245, 0.9471]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0636 (0.0475) / 0.3145 0.1385, 0.8632, 0.9049]\n",
            "Epoch #59\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0259 (0.0299) / 0.3118 0.1425, 0.9281, 0.9509]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0651 (0.0555) / 0.3145 0.1385, 0.8712, 0.8969]\n",
            "Epoch #60\n",
            "100% 12/12 [00:18<00:00,  1.52s/it, 0.0290 (0.0343) / 0.3121 0.1420, 0.9207, 0.9439]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0818 (0.0798) / 0.3145 0.1385, 0.8487, 0.8732]\n",
            "Epoch #61\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0313 (0.0266) / 0.3136 0.1427, 0.9108, 0.9408]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0664 (0.0814) / 0.3145 0.1385, 0.8612, 0.8979]\n",
            "Epoch #62\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0287 (0.0300) / 0.3128 0.1425, 0.9204, 0.9432]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0639 (0.1360) / 0.3145 0.1385, 0.8712, 0.9039]\n",
            "Epoch #63\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0267 (0.0261) / 0.3147 0.1436, 0.9271, 0.9483]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0634 (0.0602) / 0.3145 0.1385, 0.8733, 0.9035]\n",
            "Epoch #64\n",
            "100% 12/12 [00:16<00:00,  1.42s/it, 0.0281 (0.0280) / 0.3139 0.1430, 0.9237, 0.9454]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0717 (0.0689) / 0.3145 0.1385, 0.8519, 0.9026]\n",
            "Epoch #65\n",
            "100% 12/12 [00:18<00:00,  1.54s/it, 0.0266 (0.0293) / 0.3136 0.1425, 0.9265, 0.9494]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0616 (0.0528) / 0.3145 0.1385, 0.8730, 0.9049]\n",
            "Epoch #66\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0256 (0.0252) / 0.3153 0.1441, 0.9305, 0.9505]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0622 (0.0558) / 0.3145 0.1385, 0.8723, 0.9073]\n",
            "Epoch #67\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0245 (0.0250) / 0.3134 0.1434, 0.9318, 0.9527]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0682 (0.0434) / 0.3145 0.1385, 0.8602, 0.9030]\n",
            "Epoch #68\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0265 (0.0242) / 0.3131 0.1430, 0.9269, 0.9493]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0691 (0.0857) / 0.3145 0.1385, 0.8637, 0.8935]\n",
            "Epoch #69\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0256 (0.0342) / 0.3130 0.1424, 0.9296, 0.9510]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0696 (0.0578) / 0.3145 0.1385, 0.8665, 0.8963]\n",
            "Epoch #70\n",
            "100% 12/12 [00:17<00:00,  1.43s/it, 0.0247 (0.0245) / 0.3124 0.1415, 0.9332, 0.9519]\n",
            "100% 65/65 [01:17<00:00,  1.20s/it, 0.0663 (0.0558) / 0.3145 0.1385, 0.8697, 0.9020]\n",
            "Epoch #71\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0252 (0.0222) / 0.3144 0.1425, 0.9320, 0.9512]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0682 (0.0484) / 0.3145 0.1385, 0.8716, 0.8990]\n",
            "Epoch #72\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0259 (0.0258) / 0.3130 0.1432, 0.9305, 0.9494]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0677 (0.0460) / 0.3145 0.1385, 0.8687, 0.8964]\n",
            "Epoch #73\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0240 (0.0235) / 0.3138 0.1435, 0.9344, 0.9542]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0651 (0.0528) / 0.3145 0.1385, 0.8716, 0.9053]\n",
            "Epoch #74\n",
            "100% 12/12 [00:18<00:00,  1.53s/it, 0.0230 (0.0224) / 0.3114 0.1423, 0.9361, 0.9561]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0690 (0.0568) / 0.3145 0.1385, 0.8670, 0.9012]\n",
            "Epoch #75\n",
            "100% 12/12 [00:16<00:00,  1.42s/it, 0.0247 (0.0293) / 0.3139 0.1439, 0.9313, 0.9527]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0674 (0.0475) / 0.3145 0.1385, 0.8768, 0.9023]\n",
            "Epoch #76\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0265 (0.0314) / 0.3137 0.1430, 0.9295, 0.9476]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0733 (0.0480) / 0.3145 0.1385, 0.8683, 0.8963]\n",
            "Epoch #77\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0237 (0.0221) / 0.3153 0.1434, 0.9349, 0.9549]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0701 (0.0580) / 0.3145 0.1385, 0.8721, 0.8949]\n",
            "Epoch #78\n",
            "100% 12/12 [00:18<00:00,  1.50s/it, 0.0227 (0.0233) / 0.3127 0.1431, 0.9375, 0.9558]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0659 (0.0470) / 0.3145 0.1385, 0.8716, 0.9071]\n",
            "Epoch #79\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0209 (0.0227) / 0.3147 0.1433, 0.9444, 0.9600]\n",
            "100% 65/65 [01:18<00:00,  1.22s/it, 0.0685 (0.0468) / 0.3145 0.1385, 0.8750, 0.9019]\n",
            "Epoch #80\n",
            "100% 12/12 [00:16<00:00,  1.36s/it, 0.0229 (0.0213) / 0.3140 0.1426, 0.9371, 0.9554]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0787 (0.0506) / 0.3145 0.1385, 0.8693, 0.8921]\n",
            "Epoch #81\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0219 (0.0188) / 0.3130 0.1428, 0.9400, 0.9581]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0678 (0.0716) / 0.3145 0.1385, 0.8683, 0.9048]\n",
            "Epoch #82\n",
            "100% 12/12 [00:18<00:00,  1.55s/it, 0.0203 (0.0228) / 0.3133 0.1428, 0.9446, 0.9614]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0700 (0.0561) / 0.3145 0.1385, 0.8742, 0.9036]\n",
            "Epoch #83\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0210 (0.0270) / 0.3149 0.1430, 0.9448, 0.9585]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0714 (0.0474) / 0.3145 0.1385, 0.8692, 0.9032]\n",
            "Epoch #84\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0216 (0.0179) / 0.3130 0.1431, 0.9399, 0.9588]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0669 (0.0480) / 0.3145 0.1385, 0.8709, 0.9064]\n",
            "Epoch #85\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0212 (0.0249) / 0.3138 0.1440, 0.9431, 0.9582]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0769 (0.1001) / 0.3145 0.1385, 0.8708, 0.8978]\n",
            "Epoch #86\n",
            "100% 12/12 [00:18<00:00,  1.52s/it, 0.0210 (0.0202) / 0.3148 0.1431, 0.9437, 0.9596]\n",
            "100% 65/65 [01:17<00:00,  1.18s/it, 0.0750 (0.0722) / 0.3145 0.1385, 0.8733, 0.8994]\n",
            "Epoch #87\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0205 (0.0208) / 0.3135 0.1435, 0.9432, 0.9608]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0687 (0.0567) / 0.3145 0.1385, 0.8753, 0.9065]\n",
            "Epoch #88\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0196 (0.0198) / 0.3132 0.1439, 0.9458, 0.9623]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0710 (0.0830) / 0.3145 0.1385, 0.8721, 0.9076]\n",
            "Epoch #89\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0209 (0.0222) / 0.3146 0.1445, 0.9421, 0.9597]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0712 (0.0569) / 0.3145 0.1385, 0.8735, 0.9051]\n",
            "Epoch #90\n",
            "100% 12/12 [00:17<00:00,  1.43s/it, 0.0199 (0.0193) / 0.3132 0.1431, 0.9458, 0.9614]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0711 (0.0706) / 0.3145 0.1385, 0.8768, 0.9069]\n",
            "Epoch #91\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0194 (0.0172) / 0.3118 0.1424, 0.9467, 0.9619]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0769 (0.0421) / 0.3145 0.1385, 0.8735, 0.8998]\n",
            "Epoch #92\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0188 (0.0186) / 0.3144 0.1425, 0.9483, 0.9642]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0707 (0.0722) / 0.3145 0.1385, 0.8757, 0.9039]\n",
            "Epoch #93\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0187 (0.0198) / 0.3147 0.1445, 0.9490, 0.9640]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0763 (0.0455) / 0.3145 0.1385, 0.8722, 0.9030]\n",
            "Epoch #94\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0192 (0.0187) / 0.3137 0.1437, 0.9474, 0.9630]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0736 (0.0603) / 0.3145 0.1385, 0.8746, 0.9027]\n",
            "Epoch #95\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0190 (0.0186) / 0.3121 0.1428, 0.9458, 0.9639]\n",
            "100% 65/65 [01:18<00:00,  1.20s/it, 0.0817 (0.0568) / 0.3145 0.1385, 0.8733, 0.8958]\n",
            "Epoch #96\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0201 (0.0171) / 0.3125 0.1430, 0.9421, 0.9614]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0772 (0.0638) / 0.3145 0.1385, 0.8737, 0.9002]\n",
            "Epoch #97\n",
            "100% 12/12 [00:17<00:00,  1.45s/it, 0.0188 (0.0193) / 0.3132 0.1438, 0.9481, 0.9638]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0724 (0.0738) / 0.3145 0.1385, 0.8751, 0.9077]\n",
            "Epoch #98\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0189 (0.0216) / 0.3123 0.1436, 0.9468, 0.9636]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0734 (0.0887) / 0.3145 0.1385, 0.8740, 0.9082]\n",
            "Epoch #99\n",
            "100% 12/12 [00:17<00:00,  1.46s/it, 0.0193 (0.0211) / 0.3125 0.1410, 0.9458, 0.9627]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0771 (0.0734) / 0.3145 0.1385, 0.8641, 0.9061]\n",
            "Epoch #100\n",
            "100% 12/12 [00:18<00:00,  1.53s/it, 0.0191 (0.0178) / 0.3129 0.1427, 0.9465, 0.9636]\n",
            "100% 65/65 [01:17<00:00,  1.18s/it, 0.0751 (0.0609) / 0.3145 0.1385, 0.8757, 0.9039]\n",
            "Epoch #101\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0206 (0.0230) / 0.3122 0.1426, 0.9430, 0.9588]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0765 (0.0490) / 0.3145 0.1385, 0.8746, 0.9017]\n",
            "Epoch #102\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0206 (0.0216) / 0.3126 0.1420, 0.9428, 0.9593]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0757 (0.2145) / 0.3145 0.1385, 0.8751, 0.9048]\n",
            "Epoch #103\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0180 (0.0185) / 0.3133 0.1419, 0.9500, 0.9657]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0729 (0.0769) / 0.3145 0.1385, 0.8758, 0.9069]\n",
            "Epoch #104\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0177 (0.0179) / 0.3134 0.1433, 0.9518, 0.9660]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0780 (0.0319) / 0.3145 0.1385, 0.8763, 0.9029]\n",
            "Epoch #105\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0174 (0.0200) / 0.3132 0.1435, 0.9520, 0.9668]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0755 (0.0586) / 0.3145 0.1385, 0.8746, 0.9055]\n",
            "Epoch #106\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0177 (0.0223) / 0.3120 0.1425, 0.9501, 0.9657]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0764 (0.1218) / 0.3145 0.1385, 0.8780, 0.9063]\n",
            "Epoch #107\n",
            "100% 12/12 [00:18<00:00,  1.55s/it, 0.0173 (0.0189) / 0.3116 0.1408, 0.9520, 0.9663]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0756 (0.0549) / 0.3145 0.1385, 0.8773, 0.9069]\n",
            "Epoch #108\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0166 (0.0160) / 0.3125 0.1431, 0.9539, 0.9682]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0773 (0.0707) / 0.3145 0.1385, 0.8751, 0.9079]\n",
            "Epoch #109\n",
            "100% 12/12 [00:16<00:00,  1.36s/it, 0.0176 (0.0181) / 0.3126 0.1428, 0.9508, 0.9660]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0770 (0.0505) / 0.3145 0.1385, 0.8734, 0.9094]\n",
            "Epoch #110\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0172 (0.0184) / 0.3138 0.1444, 0.9527, 0.9663]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0778 (0.0683) / 0.3145 0.1385, 0.8714, 0.9072]\n",
            "Epoch #111\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0178 (0.0194) / 0.3132 0.1412, 0.9486, 0.9664]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0814 (0.0481) / 0.3145 0.1385, 0.8695, 0.9070]\n",
            "Epoch #112\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0184 (0.0223) / 0.3105 0.1401, 0.9479, 0.9648]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0757 (0.0617) / 0.3145 0.1385, 0.8760, 0.9061]\n",
            "Epoch #113\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0180 (0.0212) / 0.3139 0.1432, 0.9490, 0.9659]\n",
            "100% 65/65 [01:18<00:00,  1.22s/it, 0.0762 (0.0607) / 0.3145 0.1385, 0.8721, 0.9075]\n",
            "Epoch #114\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0181 (0.0199) / 0.3137 0.1441, 0.9492, 0.9656]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0749 (0.0719) / 0.3145 0.1385, 0.8752, 0.9091]\n",
            "Epoch #115\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0175 (0.0202) / 0.3128 0.1439, 0.9508, 0.9667]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0741 (0.0498) / 0.3145 0.1385, 0.8779, 0.9075]\n",
            "Epoch #116\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0166 (0.0161) / 0.3119 0.1422, 0.9529, 0.9686]\n",
            "100% 65/65 [01:17<00:00,  1.20s/it, 0.0786 (0.0598) / 0.3145 0.1385, 0.8763, 0.9078]\n",
            "Epoch #117\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0172 (0.0162) / 0.3131 0.1427, 0.9516, 0.9671]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0795 (0.1023) / 0.3145 0.1385, 0.8743, 0.9069]\n",
            "Epoch #118\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0170 (0.0188) / 0.3138 0.1434, 0.9529, 0.9669]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0769 (0.0893) / 0.3145 0.1385, 0.8733, 0.9098]\n",
            "Epoch #119\n",
            "100% 12/12 [00:18<00:00,  1.55s/it, 0.0181 (0.0163) / 0.3110 0.1422, 0.9491, 0.9646]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0785 (0.0577) / 0.3145 0.1385, 0.8729, 0.9042]\n",
            "Epoch #120\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0168 (0.0178) / 0.3124 0.1418, 0.9546, 0.9667]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0753 (0.0508) / 0.3145 0.1385, 0.8726, 0.9087]\n",
            "Epoch #121\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0164 (0.0158) / 0.3140 0.1437, 0.9541, 0.9691]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0820 (0.1105) / 0.3145 0.1385, 0.8770, 0.9047]\n",
            "Epoch #122\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0159 (0.0162) / 0.3126 0.1416, 0.9567, 0.9694]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0814 (0.0915) / 0.3145 0.1385, 0.8769, 0.9051]\n",
            "Epoch #123\n",
            "100% 12/12 [00:17<00:00,  1.42s/it, 0.0154 (0.0166) / 0.3137 0.1426, 0.9568, 0.9711]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0800 (0.0672) / 0.3145 0.1385, 0.8732, 0.9093]\n",
            "Epoch #124\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0155 (0.0158) / 0.3139 0.1440, 0.9572, 0.9704]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0786 (0.0523) / 0.3145 0.1385, 0.8750, 0.9102]\n",
            "Epoch #125\n",
            "100% 12/12 [00:17<00:00,  1.43s/it, 0.0155 (0.0154) / 0.3149 0.1444, 0.9565, 0.9711]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0837 (0.0800) / 0.3145 0.1385, 0.8760, 0.9073]\n",
            "Epoch #126\n",
            "100% 12/12 [00:16<00:00,  1.36s/it, 0.0157 (0.0144) / 0.3108 0.1410, 0.9565, 0.9692]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0863 (0.0570) / 0.3145 0.1385, 0.8759, 0.9023]\n",
            "Epoch #127\n",
            "100% 12/12 [00:17<00:00,  1.42s/it, 0.0155 (0.0150) / 0.3123 0.1438, 0.9562, 0.9703]\n",
            "100% 65/65 [01:18<00:00,  1.22s/it, 0.0826 (0.1129) / 0.3145 0.1385, 0.8734, 0.9087]\n",
            "Epoch #128\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0156 (0.0163) / 0.3125 0.1421, 0.9574, 0.9690]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0834 (0.0636) / 0.3145 0.1385, 0.8676, 0.9087]\n",
            "Epoch #129\n",
            "100% 12/12 [00:17<00:00,  1.42s/it, 0.0164 (0.0151) / 0.3118 0.1416, 0.9528, 0.9690]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0838 (0.0803) / 0.3145 0.1385, 0.8758, 0.9090]\n",
            "Epoch #130\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0174 (0.0178) / 0.3129 0.1422, 0.9499, 0.9661]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0837 (0.0716) / 0.3145 0.1385, 0.8770, 0.9061]\n",
            "Epoch #131\n",
            "100% 12/12 [00:17<00:00,  1.42s/it, 0.0159 (0.0134) / 0.3116 0.1431, 0.9564, 0.9687]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0835 (0.0844) / 0.3145 0.1385, 0.8755, 0.9074]\n",
            "Epoch #132\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0157 (0.0181) / 0.3133 0.1430, 0.9563, 0.9696]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0858 (0.0643) / 0.3145 0.1385, 0.8741, 0.9047]\n",
            "Epoch #133\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0154 (0.0166) / 0.3110 0.1409, 0.9572, 0.9696]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0820 (0.0438) / 0.3145 0.1385, 0.8766, 0.9066]\n",
            "Epoch #134\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0155 (0.0141) / 0.3106 0.1423, 0.9569, 0.9697]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0813 (0.0328) / 0.3145 0.1385, 0.8772, 0.9082]\n",
            "Epoch #135\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0153 (0.0153) / 0.3142 0.1434, 0.9580, 0.9707]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0842 (0.0531) / 0.3145 0.1385, 0.8760, 0.9052]\n",
            "Epoch #136\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0158 (0.0160) / 0.3115 0.1408, 0.9557, 0.9691]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0844 (0.8799) / 0.3145 0.1385, 0.8731, 0.9076]\n",
            "Epoch #137\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0146 (0.0130) / 0.3122 0.1409, 0.9598, 0.9719]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0843 (0.0702) / 0.3145 0.1385, 0.8775, 0.9057]\n",
            "Epoch #138\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0147 (0.0142) / 0.3125 0.1434, 0.9588, 0.9727]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0862 (0.0581) / 0.3145 0.1385, 0.8750, 0.9071]\n",
            "Epoch #139\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0144 (0.0151) / 0.3138 0.1430, 0.9608, 0.9730]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0856 (0.0939) / 0.3145 0.1385, 0.8744, 0.9101]\n",
            "Epoch #140\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0156 (0.0166) / 0.3129 0.1413, 0.9577, 0.9691]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0872 (0.0626) / 0.3145 0.1385, 0.8759, 0.9064]\n",
            "Epoch #141\n",
            "100% 12/12 [00:18<00:00,  1.56s/it, 0.0146 (0.0142) / 0.3132 0.1421, 0.9585, 0.9727]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0884 (0.0944) / 0.3145 0.1385, 0.8738, 0.9056]\n",
            "Epoch #142\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0153 (0.0143) / 0.3123 0.1425, 0.9578, 0.9704]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0846 (0.0494) / 0.3145 0.1385, 0.8739, 0.9073]\n",
            "Epoch #143\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0149 (0.0148) / 0.3126 0.1429, 0.9591, 0.9711]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0871 (0.0579) / 0.3145 0.1385, 0.8783, 0.9064]\n",
            "Epoch #144\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0142 (0.0169) / 0.3123 0.1431, 0.9599, 0.9732]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0867 (0.1158) / 0.3145 0.1385, 0.8735, 0.9093]\n",
            "Epoch #145\n",
            "100% 12/12 [00:16<00:00,  1.34s/it, 0.0147 (0.0165) / 0.3132 0.1430, 0.9592, 0.9715]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0876 (0.0590) / 0.3145 0.1385, 0.8725, 0.9085]\n",
            "Epoch #146\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0155 (0.0133) / 0.3147 0.1436, 0.9563, 0.9705]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0896 (0.0619) / 0.3145 0.1385, 0.8776, 0.9058]\n",
            "Epoch #147\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0144 (0.0134) / 0.3137 0.1429, 0.9604, 0.9729]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0876 (0.0475) / 0.3145 0.1385, 0.8781, 0.9042]\n",
            "Epoch #148\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0142 (0.0130) / 0.3143 0.1439, 0.9606, 0.9735]\n",
            "100% 65/65 [01:17<00:00,  1.19s/it, 0.0903 (0.0733) / 0.3145 0.1385, 0.8774, 0.9041]\n",
            "Epoch #149\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0143 (0.0154) / 0.3119 0.1421, 0.9608, 0.9717]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0863 (0.0519) / 0.3145 0.1385, 0.8774, 0.9089]\n",
            "Epoch #150\n",
            "100% 12/12 [00:16<00:00,  1.36s/it, 0.0142 (0.0129) / 0.3129 0.1437, 0.9600, 0.9731]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0875 (0.0589) / 0.3145 0.1385, 0.8787, 0.9072]\n",
            "Epoch #151\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0148 (0.0162) / 0.3121 0.1411, 0.9583, 0.9713]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0885 (0.0892) / 0.3145 0.1385, 0.8784, 0.9055]\n",
            "Epoch #152\n",
            "100% 12/12 [00:18<00:00,  1.52s/it, 0.0148 (0.0145) / 0.3132 0.1425, 0.9590, 0.9718]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0830 (0.0748) / 0.3145 0.1385, 0.8775, 0.9102]\n",
            "Epoch #153\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0144 (0.0136) / 0.3119 0.1433, 0.9599, 0.9722]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0862 (0.0644) / 0.3145 0.1385, 0.8762, 0.9077]\n",
            "Epoch #154\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0145 (0.0168) / 0.3125 0.1416, 0.9593, 0.9721]\n",
            "100% 65/65 [01:18<00:00,  1.20s/it, 0.0961 (0.1292) / 0.3145 0.1385, 0.8760, 0.8989]\n",
            "Epoch #155\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0152 (0.0152) / 0.3126 0.1417, 0.9577, 0.9704]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0893 (0.0592) / 0.3145 0.1385, 0.8772, 0.9070]\n",
            "Epoch #156\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0153 (0.0144) / 0.3127 0.1432, 0.9578, 0.9699]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0889 (0.0952) / 0.3145 0.1385, 0.8770, 0.9055]\n",
            "Epoch #157\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0139 (0.0126) / 0.3122 0.1435, 0.9617, 0.9735]\n",
            "100% 65/65 [01:18<00:00,  1.20s/it, 0.0910 (0.0550) / 0.3145 0.1385, 0.8766, 0.9074]\n",
            "Epoch #158\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0138 (0.0147) / 0.3139 0.1438, 0.9624, 0.9734]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0878 (0.0793) / 0.3145 0.1385, 0.8796, 0.9075]\n",
            "Epoch #159\n",
            "100% 12/12 [00:18<00:00,  1.55s/it, 0.0133 (0.0135) / 0.3134 0.1415, 0.9641, 0.9745]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0887 (0.1829) / 0.3145 0.1385, 0.8757, 0.9084]\n",
            "Epoch #160\n",
            "100% 12/12 [00:16<00:00,  1.34s/it, 0.0138 (0.0172) / 0.3135 0.1429, 0.9615, 0.9736]\n",
            "100% 65/65 [01:18<00:00,  1.20s/it, 0.0964 (0.0507) / 0.3145 0.1385, 0.8769, 0.9015]\n",
            "Epoch #161\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0144 (0.0134) / 0.3132 0.1437, 0.9593, 0.9723]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0910 (0.0605) / 0.3145 0.1385, 0.8781, 0.9062]\n",
            "Epoch #162\n",
            "100% 12/12 [00:17<00:00,  1.42s/it, 0.0144 (0.0165) / 0.3135 0.1428, 0.9600, 0.9723]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0881 (0.1390) / 0.3145 0.1385, 0.8766, 0.9089]\n",
            "Epoch #163\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0146 (0.0163) / 0.3127 0.1422, 0.9596, 0.9716]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0905 (0.0967) / 0.3145 0.1385, 0.8739, 0.9088]\n",
            "Epoch #164\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0147 (0.0156) / 0.3126 0.1408, 0.9588, 0.9714]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0895 (0.0789) / 0.3145 0.1385, 0.8722, 0.9083]\n",
            "Epoch #165\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0141 (0.0166) / 0.3122 0.1424, 0.9595, 0.9732]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0880 (0.0918) / 0.3145 0.1385, 0.8782, 0.9072]\n",
            "Epoch #166\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0134 (0.0145) / 0.3136 0.1426, 0.9623, 0.9744]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0927 (0.0886) / 0.3145 0.1385, 0.8772, 0.9048]\n",
            "Epoch #167\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0143 (0.0133) / 0.3116 0.1432, 0.9606, 0.9721]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0922 (0.0649) / 0.3145 0.1385, 0.8785, 0.9062]\n",
            "Epoch #168\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0140 (0.0155) / 0.3127 0.1413, 0.9602, 0.9734]\n",
            "100% 65/65 [01:16<00:00,  1.17s/it, 0.0914 (0.0628) / 0.3145 0.1385, 0.8751, 0.9089]\n",
            "Epoch #169\n",
            "100% 12/12 [00:18<00:00,  1.53s/it, 0.0146 (0.0143) / 0.3131 0.1430, 0.9595, 0.9713]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0917 (0.1028) / 0.3145 0.1385, 0.8738, 0.9100]\n",
            "Epoch #170\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0144 (0.0128) / 0.3129 0.1420, 0.9596, 0.9724]\n",
            "100% 65/65 [01:18<00:00,  1.20s/it, 0.0879 (0.1103) / 0.3145 0.1385, 0.8763, 0.9075]\n",
            "Epoch #171\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0140 (0.0132) / 0.3115 0.1417, 0.9603, 0.9730]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0957 (0.0599) / 0.3145 0.1385, 0.8765, 0.9014]\n",
            "Epoch #172\n",
            "100% 12/12 [00:18<00:00,  1.53s/it, 0.0143 (0.0156) / 0.3144 0.1434, 0.9607, 0.9722]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0933 (0.0993) / 0.3145 0.1385, 0.8796, 0.9057]\n",
            "Epoch #173\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0133 (0.0135) / 0.3131 0.1433, 0.9627, 0.9747]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0922 (0.0481) / 0.3145 0.1385, 0.8715, 0.9097]\n",
            "Epoch #174\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0137 (0.0137) / 0.3112 0.1404, 0.9615, 0.9731]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0893 (0.0667) / 0.3145 0.1385, 0.8772, 0.9083]\n",
            "Epoch #175\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0136 (0.0128) / 0.3146 0.1440, 0.9631, 0.9741]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0888 (0.0622) / 0.3145 0.1385, 0.8784, 0.9078]\n",
            "Epoch #176\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0136 (0.0137) / 0.3129 0.1432, 0.9624, 0.9739]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0938 (0.0617) / 0.3145 0.1385, 0.8789, 0.9066]\n",
            "Epoch #177\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0132 (0.0120) / 0.3119 0.1427, 0.9632, 0.9753]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0899 (0.0764) / 0.3145 0.1385, 0.8773, 0.9084]\n",
            "Epoch #178\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0132 (0.0130) / 0.3124 0.1438, 0.9635, 0.9747]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0886 (0.1573) / 0.3145 0.1385, 0.8776, 0.9103]\n",
            "Epoch #179\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0132 (0.0129) / 0.3135 0.1432, 0.9626, 0.9751]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0907 (0.0706) / 0.3145 0.1385, 0.8768, 0.9100]\n",
            "Epoch #180\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0128 (0.0116) / 0.3125 0.1431, 0.9638, 0.9760]\n",
            "100% 65/65 [01:19<00:00,  1.22s/it, 0.0947 (0.1350) / 0.3145 0.1385, 0.8775, 0.9067]\n",
            "Epoch #181\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0132 (0.0147) / 0.3133 0.1427, 0.9626, 0.9755]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0887 (0.0598) / 0.3145 0.1385, 0.8783, 0.9087]\n",
            "Epoch #182\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0131 (0.0138) / 0.3139 0.1430, 0.9636, 0.9752]\n",
            "100% 65/65 [01:18<00:00,  1.20s/it, 0.0939 (0.0938) / 0.3145 0.1385, 0.8787, 0.9075]\n",
            "Epoch #183\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0128 (0.0123) / 0.3123 0.1420, 0.9644, 0.9756]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0949 (0.0648) / 0.3145 0.1385, 0.8797, 0.9061]\n",
            "Epoch #184\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0122 (0.0126) / 0.3128 0.1436, 0.9668, 0.9774]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0927 (0.0819) / 0.3145 0.1385, 0.8787, 0.9098]\n",
            "Epoch #185\n",
            "100% 12/12 [00:16<00:00,  1.36s/it, 0.0122 (0.0124) / 0.3123 0.1433, 0.9668, 0.9766]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0925 (0.0689) / 0.3145 0.1385, 0.8772, 0.9105]\n",
            "Epoch #186\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0133 (0.0107) / 0.3143 0.1434, 0.9630, 0.9745]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0926 (0.0947) / 0.3145 0.1385, 0.8776, 0.9096]\n",
            "Epoch #187\n",
            "100% 12/12 [00:16<00:00,  1.34s/it, 0.0125 (0.0130) / 0.3140 0.1431, 0.9659, 0.9762]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0963 (0.0478) / 0.3145 0.1385, 0.8794, 0.9076]\n",
            "Epoch #188\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0123 (0.0145) / 0.3113 0.1420, 0.9658, 0.9767]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0959 (0.0662) / 0.3145 0.1385, 0.8794, 0.9091]\n",
            "Epoch #189\n",
            "100% 12/12 [00:16<00:00,  1.37s/it, 0.0126 (0.0123) / 0.3109 0.1419, 0.9650, 0.9760]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0918 (0.0758) / 0.3145 0.1385, 0.8762, 0.9092]\n",
            "Epoch #190\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0127 (0.0118) / 0.3142 0.1440, 0.9642, 0.9765]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0935 (0.2639) / 0.3145 0.1385, 0.8789, 0.9101]\n",
            "Epoch #191\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0123 (0.0137) / 0.3119 0.1413, 0.9659, 0.9765]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0941 (0.0973) / 0.3145 0.1385, 0.8757, 0.9099]\n",
            "Epoch #192\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0118 (0.0126) / 0.3121 0.1412, 0.9685, 0.9775]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0958 (0.0615) / 0.3145 0.1385, 0.8780, 0.9076]\n",
            "Epoch #193\n",
            "100% 12/12 [00:16<00:00,  1.40s/it, 0.0119 (0.0115) / 0.3137 0.1420, 0.9670, 0.9776]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.0952 (0.0593) / 0.3145 0.1385, 0.8799, 0.9093]\n",
            "Epoch #194\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0125 (0.0140) / 0.3134 0.1421, 0.9655, 0.9763]\n",
            "100% 65/65 [01:18<00:00,  1.21s/it, 0.0972 (0.0474) / 0.3145 0.1385, 0.8796, 0.9066]\n",
            "Epoch #195\n",
            "100% 12/12 [00:16<00:00,  1.41s/it, 0.0120 (0.0135) / 0.3121 0.1430, 0.9679, 0.9768]\n",
            "100% 65/65 [01:18<00:00,  1.20s/it, 0.0979 (0.0933) / 0.3145 0.1385, 0.8783, 0.9080]\n",
            "Epoch #196\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0121 (0.0108) / 0.3139 0.1437, 0.9672, 0.9770]\n",
            "100% 65/65 [01:16<00:00,  1.17s/it, 0.0933 (0.1038) / 0.3145 0.1385, 0.8768, 0.9110]\n",
            "Epoch #197\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0124 (0.0130) / 0.3107 0.1417, 0.9648, 0.9764]\n",
            "100% 65/65 [01:18<00:00,  1.20s/it, 0.0968 (0.0692) / 0.3145 0.1385, 0.8770, 0.9095]\n",
            "Epoch #198\n",
            "100% 12/12 [00:16<00:00,  1.38s/it, 0.0123 (0.0114) / 0.3138 0.1425, 0.9665, 0.9764]\n",
            "100% 65/65 [01:18<00:00,  1.20s/it, 0.0969 (0.1925) / 0.3145 0.1385, 0.8788, 0.9098]\n",
            "Epoch #199\n",
            "100% 12/12 [00:16<00:00,  1.39s/it, 0.0119 (0.0113) / 0.3111 0.1418, 0.9669, 0.9773]\n",
            "100% 65/65 [01:16<00:00,  1.18s/it, 0.1001 (0.0752) / 0.3145 0.1385, 0.8800, 0.9083]\n",
            "100% 65/65 [02:14<00:00,  2.07s/it, 0.0548 (0.0443) / 0.3145 0.1385, 0.8593, 0.8982]\n",
            "100% 64/64 [01:42<00:00,  1.61s/it, 0.0543 (0.0478) / 0.3167 0.1369, 0.8587, 0.9006]\n",
            "100% 128/128 [3:16:06<00:00, 91.92s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports -> stavit sve importe ako nisu vec navedeni\n",
        "\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "import collections\n",
        "import pandas\n",
        "\n",
        "import click\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.signal\n",
        "import skimage.draw\n",
        "import torch\n",
        "import torchvision\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "Q-lMCrPSI5UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Projekt je organiziran u obliku python package-a. Vrhovni modul ***echonet*** se sastoji od datoteka \\_\\_init__.py, \\_\\_main__.py, \\_\\_version__.py, config.py i submodula ***datasets*** i ***utils***. Submodul ***datasets*** sadrži datoteke \\_\\_init__.py i echo.py, a submodul ***utils*** \\_\\_init__.py, segmentation.py i video.py. Cijelu strukturu modula echonet je moguće prikazati na sljedeći način:<br>\n",
        "<li>echonet</li>\n",
        "<ul>\n",
        "<li>__init__.py</li>\n",
        "<li>__main__.py</li>\n",
        "<li>__version__.py</li>\n",
        "<li>config.py</li>\n",
        "<li>datasets\n",
        "<ul>\n",
        "<li>__init__.py</li>\n",
        "<li>echo.py</li>\n",
        "</ul>\n",
        "</li>\n",
        "<li>utils\n",
        "<ul>\n",
        "<li>__init__.py</li>\n",
        "<li>segmentation.py</li>\n",
        "<li>video.py</li>\n",
        "</ul>\n",
        "</li>\n",
        "</ul>\n",
        "<br>\n",
        "Datoteka __init__.py se koristi kako bi se naznačilo da se direktorij koristi kao python package. Poziva se pri importanju modula, a obično se koristi za inicijalizaciju package-a. Datoteka __main__.py predstavlja sučelje package-a prema komandnoj liniji, odnosno ta datoteka se automatski izvršava pri pozivu package-a kao skripte iz terminala, dok datoteka __version__.py daje informaciju o trenutnoj verziji.\n",
        "\n"
      ],
      "metadata": {
        "id": "WLDTu_blK5xN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## segmentation.py"
      ],
      "metadata": {
        "id": "k8YXI0naIz1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datoteka segmentation.py započinje importanjem potrebnih modula među kojima je zanimljiv modul ***click***. Ovaj modul omogućava kreiranje sučelja prema komandnoj liniji na brz i jednostavan način. Omogućava ugnježivanje naredbi, učitavanje podnaredbi tijekom izvođenja i automatsko generiranje *help* stranice. Naredba @click.command() definira ime naredbe kojom se skripta u terminalu poziva, @click.option() definira argumente koje je moguće proslijediti skripti prilikom pokretanja. Parametar *default* određuje vrijednost argumenta kada ona nije definirana pri pozivu, dok parametar *type* određuje tip vrijednosti koju taj argument prima."
      ],
      "metadata": {
        "id": "Aj3qGGAlZM1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "import time\n",
        "\n",
        "import click\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.signal\n",
        "import skimage.draw\n",
        "import torch\n",
        "import torchvision\n",
        "import tqdm\n",
        "\n",
        "import echonet\n",
        "\n",
        "\n",
        "@click.command(\"segmentation\")\n",
        "@click.option(\"--data_dir\", type=click.Path(exists=True, file_okay=False), default=None)\n",
        "@click.option(\"--output\", type=click.Path(file_okay=False), default=None)\n",
        "@click.option(\"--model_name\", type=click.Choice(\n",
        "    sorted(name for name in torchvision.models.segmentation.__dict__\n",
        "           if name.islower() and not name.startswith(\"__\") and callable(torchvision.models.segmentation.__dict__[name]))),\n",
        "    default=\"deeplabv3_resnet50\")\n",
        "@click.option(\"--pretrained/--random\", default=False)\n",
        "@click.option(\"--weights\", type=click.Path(exists=True, dir_okay=False), default=None)\n",
        "@click.option(\"--run_test/--skip_test\", default=False)\n",
        "@click.option(\"--save_video/--skip_video\", default=False)\n",
        "@click.option(\"--num_epochs\", type=int, default=50)\n",
        "@click.option(\"--lr\", type=float, default=1e-5)\n",
        "@click.option(\"--weight_decay\", type=float, default=0)\n",
        "@click.option(\"--lr_step_period\", type=int, default=None)\n",
        "@click.option(\"--num_train_patients\", type=int, default=None)\n",
        "@click.option(\"--num_workers\", type=int, default=4)\n",
        "@click.option(\"--batch_size\", type=int, default=20)\n",
        "@click.option(\"--device\", type=str, default=None)\n",
        "@click.option(\"--seed\", type=int, default=0)"
      ],
      "metadata": {
        "id": "s4nKaU-BbUvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metoda **run** obavlja ...\n",
        "Ona prima argumente:\n",
        "- **data_dir** koji prima putanju direktorija u kojem se nalazi dataset\n",
        "-*output* kojom je definirana putanja direktorija u kojem će se spremiti izlazni podaci\n",
        "- **model_name** definira model koji će se koristiti za segmentaciju\n",
        "- **pretrained** određuje hoće li model koristiti pretrenirane težine\n",
        "- **weights** predstavlja putanju do direktorija u kojem se nalaze inicijalizacijske težine modela\n",
        "- **run_test** određuje hoćemo li nad modelom provesti test\n",
        "- **save_video** hoćemo li spremiti segmentirani video\n",
        "- **num_epochs** definira broj epoha koji će se izvršiti pri treniranju modela\n",
        "- **lr** definira vrijednost parametra *Learning rate* u algoritmu učenja *Stochastic Gradient Descent*. Taj parametar određuje intenzitet kojim se mijenjaju težine modela u svakom koraku učenja\n",
        "- **weight_decay** je dodatni parametar koji definira eksponencijalno opadanje promjena težina prema nuli\n",
        "- **lr_step_period** predstavlja period u kojem dolazi do opadanja parametra *learning rate*, defaultne vrijednosti jednake beskonačnosti\n",
        "- **num_workers** je broj podprocesa koji učitavaju podatke, *batch_size* broj uzoraka po *batchu*\n",
        "- **device** definira uređaj na kojem se izvršava skripta."
      ],
      "metadata": {
        "id": "0HawAXyjbabd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(\n",
        "    data_dir=None,\n",
        "    output=None,\n",
        "\n",
        "    model_name=\"deeplabv3_resnet50\",\n",
        "    pretrained=False,\n",
        "    weights=None,\n",
        "\n",
        "    run_test=False,\n",
        "    save_video=False,\n",
        "    num_epochs=50,\n",
        "    lr=1e-5,\n",
        "    weight_decay=1e-5,\n",
        "    lr_step_period=None,\n",
        "    num_train_patients=None,\n",
        "    num_workers=4,\n",
        "    batch_size=20,\n",
        "    device=None,\n",
        "    seed=0,\n",
        "):"
      ],
      "metadata": {
        "id": "a9Uz-5Mxb-O2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na samom početku metode *run* se resetiraju generatori slučajnih brojeva (postavljanje parametra *seed* na 0). Zatim se metodom *os.path.join()* vrši interakcija sa operacijskim sustavom i stvara jedinstvena izlazna putanja, a metodom *os.makedirs()* se rekurzivno stvara cijelo podstablo direktorija prema navedenoj putanji, Parametar *exist_ok* je postavljen na vrijednost True što označava da se neće prijaviti greška *FileExistsError* ukoliko željeno podstablo već postoji. Sljedećim linijama koda se učitava željeni model iz modula *torchvision* te se vrši postavljanje posljednjeg izlaznog sloja mreže na sloj dvodimenzionalne konvolucije sa jednim izlaznim kanalom. "
      ],
      "metadata": {
        "id": "lGPqD0_UQ0dR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Seed RNGs\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # Set default output directory\n",
        "    if output is None:\n",
        "        output = os.path.join(\"output\", \"segmentation\", \"{}_{}\".format(model_name, \"pretrained\" if pretrained else \"random\"))\n",
        "    os.makedirs(output, exist_ok=True)\n",
        "\n",
        "    # Set device for computations\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Set up model\n",
        "    model = torchvision.models.segmentation.__dict__[model_name](pretrained=pretrained, aux_loss=False)\n",
        "\n",
        "    model.classifier[-1] = torch.nn.Conv2d(model.classifier[-1].in_channels, 1, kernel_size=model.classifier[-1].kernel_size)  # change number of outputs to 1"
      ],
      "metadata": {
        "id": "i3QvVi1WkMCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ukoliko je to definirano, provjerava li se da li je dostupno postaviti *device* na \"cuda\", ukoliko nije postavlja se na \"cpu\". Ako je \"cuda\", tada se prethodno definirani model paralelizira na najvišem levelu na način da se model dijele na *chunk-ove* dimenzije definirane batch_size-om i replicira na svaki dostupni uređaj gdje svaki dio modela prima odgovarajući dio ulaza. "
      ],
      "metadata": {
        "id": "_ZTfKnRpmuB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if device.type == \"cuda\":\n",
        "        model = torch.nn.DataParallel(model)\n",
        "    model.to(device)"
      ],
      "metadata": {
        "id": "tMcngmhEqd6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Program učitava prethodno spremljene težine modela, ukoliko su dostupne, postavlja parametre za optimiziranje treniranja te pomoću metode *get_mean_and_std* iz submodula *utils* računa statističke parametre (srednje grešku i standardnu devijaciju) podataka za treniranje."
      ],
      "metadata": {
        "id": "fEXR0d8Qqp5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if weights is not None:\n",
        "        checkpoint = torch.load(weights)\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "    # Set up optimizer\n",
        "    optim = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "    if lr_step_period is None:\n",
        "        lr_step_period = math.inf\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optim, lr_step_period)\n",
        "\n",
        "    # Compute mean and std\n",
        "    mean, std = echonet.utils.get_mean_and_std(echonet.datasets.Echo(root=data_dir, split=\"train\"))"
      ],
      "metadata": {
        "id": "uisg01TxsKx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objekt kwargs je *dictionary* u kojem se pohranjuju key-value parovi koji se prosljeđuju kao parametri metodi *echonet.datasets.Echo* koja vraća odgovarajući *dataset*. Ukoliko je definirani broj pacijenata manji od dužine dataset-a, tada se slučajnim izborom odabire odgovaraući broj uzoraka iz dataseta."
      ],
      "metadata": {
        "id": "r8yBS8R6sNgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " tasks = [\"LargeFrame\", \"SmallFrame\", \"LargeTrace\", \"SmallTrace\"]\n",
        "    kwargs = {\"target_type\": tasks,\n",
        "              \"mean\": mean,\n",
        "              \"std\": std\n",
        "              }\n",
        "\n",
        "    # Set up datasets and dataloaders\n",
        "    dataset = {}\n",
        "    dataset[\"train\"] = echonet.datasets.Echo(root=data_dir, split=\"train\", **kwargs)\n",
        "    if num_train_patients is not None and len(dataset[\"train\"]) > num_train_patients:\n",
        "        # Subsample patients (used for ablation experiment)\n",
        "        indices = np.random.choice(len(dataset[\"train\"]), num_train_patients, replace=False)\n",
        "        dataset[\"train\"] = torch.utils.data.Subset(dataset[\"train\"], indices)\n",
        "    dataset[\"val\"] = echonet.datasets.Echo(root=data_dir, split=\"val\", **kwargs)"
      ],
      "metadata": {
        "id": "0M67XUGptx7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iz datoteke *checkpoint.pt*,koja se nalazi u izlaznom direktoriju, se učitavaju parametri modela. Isto tako učitavaju se parametri objekta optim koji na temelju sadašnjih parametara modela računa gradijente i nove vrijednosti parametara. Treba napomenuti da je ovim mehanizmom moguće pojedinačno pokretati epohe treniranja i slijedno ih nastavljati jednu na drugu, pri čemu se u *checkpoint[\"epoch\"]* sprema redni broj prethodno obrađene epohe, a u *checkpoint[\"best_loss\"]* najmanja vrijednost gubitka tokom validacije u bilo kojoj dosadašnjoj epohi. \n",
        "\n",
        "Ukoliko nije moguće učitati sadržaj datoteke *checkpoint.pt*, treniranje modela se pokreće od početne (prve) epohe"
      ],
      "metadata": {
        "id": "zfdsOLGMkSbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(output, \"log.csv\"), \"a\") as f:\n",
        "        epoch_resume = 0\n",
        "        bestLoss = float(\"inf\")\n",
        "        try:\n",
        "            # Attempt to load checkpoint\n",
        "            checkpoint = torch.load(os.path.join(output, \"checkpoint.pt\"))\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            optim.load_state_dict(checkpoint['opt_dict'])\n",
        "            scheduler.load_state_dict(checkpoint['scheduler_dict'])\n",
        "            epoch_resume = checkpoint[\"epoch\"] + 1\n",
        "            bestLoss = checkpoint[\"best_loss\"]\n",
        "            f.write(\"Resuming from epoch {}\\n\".format(epoch_resume))\n",
        "        except FileNotFoundError:\n",
        "            f.write(\"Starting run from scratch\\n\")"
      ],
      "metadata": {
        "id": "gcq7nIkVnFyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upotrebom for petlje se nastavlja izvršavanje postupka treniranja od trenutno dostignute epohe do krajnje definirane epohe. U svakoj iteraciji petlje se provodi treniranje i validacija modela. Početno odgovarajući dio dataset-a pošalje kao parametar konstruktoru objekta *dataloader* klase *torch.utils.data.DataLoader* čime se omogućuje jednostavan obilazak podataka, što je i detaljno objašnjeno u nastavku teksta. Objekt *dataloader* se kao parametar prosljeđuje metodi *run_epoch* . Na temelju njenih povratnih vrijednosti se računaju parametri *large_dice*, *small_dice*, *overall_dice*.\n",
        "\n",
        "Nakon završetka metode run_epoch vršimo ispis rezultata obrade u datoteku log.cvs u izlaznom direktoriju. Tu su prikazani razni parametri poput rednog broja epohe, maksimalne alocirane memorije, parametara overall_dice, small_dice, vremena izvršavanja itd...\n",
        "\n"
      ],
      "metadata": {
        "id": "HB7MWtjsnG6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epoch_resume, num_epochs):\n",
        "            print(\"Epoch #{}\".format(epoch), flush=True)\n",
        "            for phase in ['train', 'val']:\n",
        "                start_time = time.time()\n",
        "                for i in range(torch.cuda.device_count()):\n",
        "                    torch.cuda.reset_peak_memory_stats(i)\n",
        "\n",
        "                ds = dataset[phase]\n",
        "                dataloader = torch.utils.data.DataLoader(\n",
        "                    ds, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=(device.type == \"cuda\"), drop_last=(phase == \"train\"))\n",
        "\n",
        "                loss, large_inter, large_union, small_inter, small_union = echonet.utils.segmentation.run_epoch(model, dataloader, phase == \"train\", optim, device)\n",
        "                overall_dice = 2 * (large_inter.sum() + small_inter.sum()) / (large_union.sum() + large_inter.sum() + small_union.sum() + small_inter.sum())\n",
        "                large_dice = 2 * large_inter.sum() / (large_union.sum() + large_inter.sum())\n",
        "                small_dice = 2 * small_inter.sum() / (small_union.sum() + small_inter.sum())\n",
        "                f.write(\"{},{},{},{},{},{},{},{},{},{},{}\\n\".format(epoch,\n",
        "                                                                    phase,\n",
        "                                                                    loss,\n",
        "                                                                    overall_dice,\n",
        "                                                                    large_dice,\n",
        "                                                                    small_dice,\n",
        "                                                                    time.time() - start_time,\n",
        "                                                                    large_inter.size,\n",
        "                                                                    sum(torch.cuda.max_memory_allocated() for i in range(torch.cuda.device_count())),\n",
        "                                                                    sum(torch.cuda.max_memory_reserved() for i in range(torch.cuda.device_count())),\n",
        "                                                                    batch_size))\n",
        "                f.flush()\n",
        "            scheduler.step()"
      ],
      "metadata": {
        "id": "vtDOI6J8sfTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nakon poziva metode run_epoch vrši se spremanje dosadašnjih rezultata obrade u u dictionary *save* koji se sprema u izlazni direktorij pod već navedenim nazivom \"checkpoint.pt\". Ukoliko je gubitak upravo obrađene epohe manji od najmanjeg dosadašnjeg gubitka, dictionary *save* se sprema u datoteku *best.pt*."
      ],
      "metadata": {
        "id": "-dbeyyZxtpdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Save checkpoint\n",
        "            save = {\n",
        "                'epoch': epoch,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'best_loss': bestLoss,\n",
        "                'loss': loss,\n",
        "                'opt_dict': optim.state_dict(),\n",
        "                'scheduler_dict': scheduler.state_dict(),\n",
        "            }\n",
        "            torch.save(save, os.path.join(output, \"checkpoint.pt\"))\n",
        "            if loss < bestLoss:\n",
        "                torch.save(save, os.path.join(output, \"best.pt\"))\n",
        "                bestLoss = loss"
      ],
      "metadata": {
        "id": "NG9qBTZGudT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nakon obrade svih epoha model učitava parametre modela iz epohe sa najmanjim gubitkom.\n",
        "Ukoliko je argument *run_test* zadan kao True, izvršava se testiranje modela. Metodom echonet.datasets.Echo se učitava dio dataseta predviđen za testiranje i validaciju. Ponovno se formira objekt dataloader koji omogućuje lakše rukovanje sa podacima, a zatim se metodom run_epoch pokreće testiranje i validacija. Provodi se proračun već objašnjenih parametara *overall_dice*, *small_dice*, *large_dice*. Razlika je što su to ovog puta jednodimenzinalne liste, duljine jednake broju uzoraka dataset-a. Dakle, za svaki uzorak dataset-a, odnosno svaki ehokardiogram se računaju zasebni parametri spremljeni kao pojedinačni element liste i potom spremaju u odgovarajuće datoteke *val_dice.csv*, odnosno *test_dice.csv*."
      ],
      "metadata": {
        "id": "eqdtyhJ_ueK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if run_test:\n",
        "            # Run on validation and test\n",
        "            for split in [\"val\", \"test\"]:\n",
        "                dataset = echonet.datasets.Echo(root=data_dir, split=split, **kwargs)\n",
        "                dataloader = torch.utils.data.DataLoader(dataset,\n",
        "                                                         batch_size=batch_size, num_workers=num_workers, shuffle=False, pin_memory=(device.type == \"cuda\"))\n",
        "                loss, large_inter, large_union, small_inter, small_union = echonet.utils.segmentation.run_epoch(model, dataloader, False, None, device)\n",
        "\n",
        "                overall_dice = 2 * (large_inter + small_inter) / (large_union + large_inter + small_union + small_inter)\n",
        "                large_dice = 2 * large_inter / (large_union + large_inter)\n",
        "                small_dice = 2 * small_inter / (small_union + small_inter)\n",
        "                with open(os.path.join(output, \"{}_dice.csv\".format(split)), \"w\") as g:\n",
        "                    g.write(\"Filename, Overall, Large, Small\\n\")\n",
        "                    for (filename, overall, large, small) in zip(dataset.fnames, overall_dice, large_dice, small_dice):\n",
        "                        g.write(\"{},{},{},{}\\n\".format(filename, overall, large, small))\n",
        "\n",
        "                f.write(\"{} dice (overall): {:.4f} ({:.4f} - {:.4f})\\n\".format(split, *echonet.utils.bootstrap(np.concatenate((large_inter, small_inter)), np.concatenate((large_union, small_union)), echonet.utils.dice_similarity_coefficient)))\n",
        "                f.write(\"{} dice (large):   {:.4f} ({:.4f} - {:.4f})\\n\".format(split, *echonet.utils.bootstrap(large_inter, large_union, echonet.utils.dice_similarity_coefficient)))\n",
        "                f.write(\"{} dice (small):   {:.4f} ({:.4f} - {:.4f})\\n\".format(split, *echonet.utils.bootstrap(small_inter, small_union, echonet.utils.dice_similarity_coefficient)))\n",
        "                f.flush()"
      ],
      "metadata": {
        "id": "OcWzYpTSykx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "U idućem koraku, ukoliko parametar *save_video* ima vrijednost True i ukoliko u izlaznom direktoriju u poddirektoriju *videos* ne postoje sve datoteke imena iz liste *dataloader.dataset.fnames*, odnosno svi videi iz testnog dijela *dataset-a*, pokreće se blok koda koji ima sljedeće funkcionalnosti.\n",
        "\n",
        "Metoda *model.eval()* isključuje određene slojeve modela koji se ponašaju drugačije za vrijeme treniranja i evaluacije. To bi primjerice bili *DropOut* i *BatchNorm* slojevi.\n",
        "\n",
        "Metodom *torch.no_grad()* se mijenja kontekst modela čime se isključuju algoritmi za gradijentne proračune. Ova metoda rezultira uštedom u potrošnji memorije prilikom proračuna.\n",
        "\n",
        "Obilazimo sve uzorke (videe) u testnom dataset-u i pomoću metode *tqdm.tqdm(dataloader)* pratimo napredak na *progress bar-u*. Pošto, bi segmentacija cijelog videa bila riskantna zbog potencijalne prevelike duljine videa, video se segmentira u manjim dijelovima duljine tj. brojem *frameova* određenim parametrom *batch_size*. Takvi segmentirani odsječci se naposljetku konkataniraju u jedan cjelovit segmentirani video. "
      ],
      "metadata": {
        "id": "v_7_UWvWyqe9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## utils/\\_\\_init\\_\\_.py"
      ],
      "metadata": {
        "id": "aSdQjj-GT5O5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link text](https://)### loadvideo()"
      ],
      "metadata": {
        "id": "Yc8Ui6bfVPdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metoda za argument prima putanju/path do videa koji je potrebno učitati. Učitavanje se izvodi korištenjem cv2(OpenCV 2) modula. \n",
        "\n",
        "Prvo se putem `cv2.VideoCapture` metode definira video objekt iz kojeg se izvlače informacije o rezoluciji(width*height) i broju frame-ova videa. Podaci za video se zatim učitavaju frame-by-frame i to na način da se za svaki frame vrate R,G,B vrijednosti u obliku niza od 3 8-bitna integera/vrijednosti 0-255) za svaki njegov pixel.\n",
        "\n",
        "Nakon učitavanja podataka za sve frame-ove videa rezultat je tenzor čiji je format [frame][X][Y] = [R,G,B] odnosno [frame, height, width,channels]. Za potrebe našeg računanja želimo [channels, frame, height, width] format što postižemo korištenjem **numpy** `transpose()` metode koja mijenja položaj osi tenzora."
      ],
      "metadata": {
        "id": "RYIx1KHulm-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadvideo(filename: str) -> np.ndarray:\n",
        "\n",
        "    if not os.path.exists(filename):\n",
        "        raise FileNotFoundError(filename)\n",
        "    # Kreiraj video objekt\n",
        "    capture = cv2.VideoCapture(filename)\n",
        "\n",
        "    frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    # Tensor [f,h,w,c] formata -> elementi tenzora su 3-člani nizovi 8-bitnih integera\n",
        "    v = np.zeros((frame_count, frame_height, frame_width, 3), np.uint8)\n",
        "\n",
        "    for count in range(frame_count):\n",
        "        # Frame-by-frame čitanje\n",
        "        ret, frame = capture.read()\n",
        "        # Ret označava je li frame procitan ispravno\n",
        "        # Frame je matrica s 3-članim nizovima kao elementima\n",
        "        if not ret:\n",
        "            raise ValueError(\"Failed to load frame #{} of {}.\".format(count, filename))\n",
        "        # Note that the default color format in OpenCV is often referred to as RGB but it is actually BGR (the bytes are reversed) -> pretvori u RGB format\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        # Za zadani frame postavi pročitane R,G,B vrijednosti za svaki piksel\n",
        "        v[count, :, :] = frame\n",
        "    # Transpose mehanizam -> 3. os trenutnog tenzora postaje prva os novog tenzora, prva os trenutnog tenzora postaje druga os novog tenzora itd.\n",
        "    # Prije: [f,h,w,c]\n",
        "    v = v.transpose((3, 0, 1, 2))\n",
        "    # Nakon: [c,f,h,w]\n",
        "\n",
        "    return v"
      ],
      "metadata": {
        "id": "8BUSTgVNo75e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### savevideo()"
      ],
      "metadata": {
        "id": "rt07q-a4Uh6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AN3hfT54VuwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def savevideo(filename: str, array: np.ndarray, fps: typing.Union[float, int] = 1):\n",
        "    c, _, height, width = array.shape\n",
        "\n",
        "    if c != 3:\n",
        "        raise ValueError(\"savevideo expects array of shape (channels=3, frames, height, width), got shape ({})\".format(\", \".join(map(str, array.shape))))\n",
        "    fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
        "    out = cv2.VideoWriter(filename, fourcc, fps, (width, height))\n",
        "\n",
        "                                # f, w ,h , c redoslijed\n",
        "    for frame in array.transpose((1, 2, 3, 0)):\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "        out.write(frame)"
      ],
      "metadata": {
        "id": "HGHhdvmBVqjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FDq3_br-Qgzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_mean_and_std()\n",
        "\n",
        "\n",
        "$$\n",
        "( \\frac{1}{n} \\sum_{i=i}^{n} x_{i} ) \\\\\n",
        " \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^N (x_i - \\overline{x})^2}\n",
        "$$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7HQCboQLUo0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_SzIGNIHV0v3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mean_and_std(dataset: torch.utils.data.Dataset,\n",
        "                     samples: int = 128,\n",
        "                     batch_size: int = 8,\n",
        "                     num_workers: int = 4):\n",
        "    \"\"\"Computes mean and std from samples from a Pytorch dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset (torch.utils.data.Dataset): A Pytorch dataset.\n",
        "            ``dataset[i][0]'' is expected to be the i-th video in the dataset, which\n",
        "            should be a ``torch.Tensor'' of dimensions (channels=3, frames, height, width)\n",
        "        samples (int or None, optional): Number of samples to take from dataset. If ``None'', mean and\n",
        "            standard deviation are computed over all elements.\n",
        "            Defaults to 128.\n",
        "        batch_size (int, optional): how many samples per batch to load\n",
        "            Defaults to 8.\n",
        "        num_workers (int, optional): how many subprocesses to use for data\n",
        "            loading. If 0, the data will be loaded in the main process.\n",
        "            Defaults to 4.\n",
        "\n",
        "    Returns:\n",
        "       A tuple of the mean and standard deviation. Both are represented as np.array's of dimension (channels,).\n",
        "    \"\"\"\n",
        "\n",
        "    if samples is not None and len(dataset) > samples:\n",
        "        indices = np.random.choice(len(dataset), samples, replace=False)\n",
        "        dataset = torch.utils.data.Subset(dataset, indices)\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "\n",
        "    n = 0  # number of elements taken (should be equal to samples by end of for loop)\n",
        "    s1 = 0.  # sum of elements along channels (ends up as np.array of dimension (channels,))\n",
        "    s2 = 0.  # sum of squares of elements along channels (ends up as np.array of dimension (channels,))\n",
        "    for (x, *_) in tqdm.tqdm(dataloader):\n",
        "        x = x.transpose(0, 1).contiguous().view(3, -1)\n",
        "        n += x.shape[1]\n",
        "        s1 += torch.sum(x, dim=1).numpy()\n",
        "        s2 += torch.sum(x ** 2, dim=1).numpy()\n",
        "    mean = s1 / n  # type: np.ndarray\n",
        "    std = np.sqrt(s2 / n - mean ** 2)  # type: np.ndarray\n",
        "\n",
        "    mean = mean.astype(np.float32)\n",
        "    std = std.astype(np.float32)\n",
        "\n",
        "    return mean, std"
      ],
      "metadata": {
        "id": "umOjWlHKVxDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### bootstrap()"
      ],
      "metadata": {
        "id": "EFPtkCWGUzuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HQWDnJbbV5ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap(a, b, func, samples=10000):\n",
        "    \"\"\"Computes a bootstrapped confidence intervals for ``func(a, b)''.\n",
        "\n",
        "    Args:\n",
        "        a (array_like): first argument to `func`.\n",
        "        b (array_like): second argument to `func`.\n",
        "        func (callable): Function to compute confidence intervals for.\n",
        "            ``dataset[i][0]'' is expected to be the i-th video in the dataset, which\n",
        "            should be a ``torch.Tensor'' of dimensions (channels=3, frames, height, width)\n",
        "        samples (int, optional): Number of samples to compute.\n",
        "            Defaults to 10000.\n",
        "\n",
        "    Returns:\n",
        "       A tuple of (`func(a, b)`, estimated 5-th percentile, estimated 95-th percentile).\n",
        "    \"\"\"\n",
        "    a = np.array(a)\n",
        "    b = np.array(b)\n",
        "\n",
        "    bootstraps = []\n",
        "    for _ in range(samples):\n",
        "        ind = np.random.choice(len(a), len(a))\n",
        "        bootstraps.append(func(a[ind], b[ind]))\n",
        "    bootstraps = sorted(bootstraps)\n",
        "\n",
        "    return func(a, b), bootstraps[round(0.05 * len(bootstraps))], bootstraps[round(0.95 * len(bootstraps))]"
      ],
      "metadata": {
        "id": "0ctjDKqCV5v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dice_similarity_coefficient()"
      ],
      "metadata": {
        "id": "bzY_2uZHU5s3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GrgmfgFqV8n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_similarity_coefficient(inter, union):\n",
        "    \"\"\"Computes the dice similarity coefficient.\n",
        "\n",
        "    Args:\n",
        "        inter (iterable): iterable of the intersections\n",
        "        union (iterable): iterable of the unions\n",
        "    \"\"\"\n",
        "    return 2 * sum(inter) / (sum(union) + sum(inter))"
      ],
      "metadata": {
        "id": "BG0Bro50V-4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## echo.py"
      ],
      "metadata": {
        "id": "-akTasgXE-JD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Budući da želimo odvojiti način učitavanja i rukovanja s podacima od naše programske logike vezane uz segmentaciju zbog bolje modularnosti, čitljivosti i lakšeg održavanja kreiran je **echo.py** modul koji definira procedure koje će biti zajedničke svakoj instanci iz dataseta za treniranje, testiranje i validaciju. \n",
        "\n",
        "Zbog kompleksnosti domene računalnog vida, pisanje programskog koda za rukovanje s podacima \"od nule\" bilo bi iznimno zahtjevno i dugotrajno.\n",
        "\n",
        " Međutim, popularnost područja umjetne inteligencije i strojnog učenja u računalnom svijetu posljednih nekoliko desetljeća uz popratni eksponencijalni rast performansi hardeverskih tehnologija za posljedicu je imala razvoj različitih biblioteka i programskih okvira koji su znatno ubrzali i olakšali razvoj projekata u zadanim domenama.\n",
        "\n",
        " U prethodno navedene programske okvire spada i **PyTorch** koji je korišten u ovom projektu zajedno sa **TorchVision** bibliotekom integriranom unutar njega i specijaliziranom za područje računalnog vida.\n",
        "\n",
        " Kao i svaki programski okvir, **PyTorch** nam pruža različite funkcionalnosti kroz svoje sučelje s ciljem ponovnog korištenja logike koja je zajednička većini projekata u domeni strojnog učenja, ali uz paralelno smanjenje fleksibilnosti budući da moramo slijediti njegova \"pravila\".\n",
        "\n",
        " Upravo je takav princip korišten kod definiranja **dataloadera** za učitavanja dataseta i operacija nad samim instancama dataseta."
      ],
      "metadata": {
        "id": "mBYxE0nKFp3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Dataloader\n",
        "Osim definiranja načina učitavanja podataka za potrebe našeg modela, Dataloader služi kao i dodatna razina apstrakcije unutar PyTorch frameworka koja nam omogućava jednostavno iteriranje kroz učitane podatke. Svi parametri PyTorch Dataloader konstruktora navedeni su u [dokumentaciji](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), a ovdje ćemo navesti one koji su korišteni u ovom projektu:\n",
        "- **dataset**: najvažniji argument koji odgovara prethodno kreiranoj dataset instanci. Više detalja u **PyTorch Dataset** poglavlju.\n",
        "- **batch_size**: jedan od najvažnijih hiperparametara modela koji može drastično utjecati na njegove performanse. Definira broj instanci dataset-a koje se obrađuju u jednoj iteraciji. U našem slučaju ovaj broj je 20 ili 10 ovisno o situaciji.\n",
        "- **num_workers**: broj podprocesa koji će biti korišteni prilikom učitavanja podataka. Ovaj parametar omogućuje paralelizaciju učitavanja podataka. Detaljnije na [linku](https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading).\n",
        "- **shuffle**: definira hoće li se u svakoj epohi uzimati isti podaci po redu kako su navedeni(*false*) ili će se u svakoj epohi uzimati drukčiji podaci na random način(*true*). Ovaj parametar je dosta bitan ukoliko želimo izbjeći **overfitting** modela te ga pri tome postavljamo na *true*.\n",
        "- **pin_memory**: definira hoće li podaci učitani podaci biti kopirani u posebni \"pinned memeory\" dio koji služi za prijenos podataka između CPU host i GPU device. Ovaj parametar može značajno utjecati na brzinu prijenosa podataka između host i device, ali naravno zahtjeva dodatne resurse kod host-a. Više informacija o ovom mehanizmu: [članak](https://leimao.github.io/blog/Page-Locked-Host-Memory-Data-Transfer/), [NVIDIA](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwirsMHB1LT4AhWC8rsIHRCuC5sQFnoECAcQAw&url=https%3A%2F%2Fengineering.purdue.edu%2F~smidkiff%2Fece563%2FNVidiaGPUTeachingToolkit%2FMod14DataXfer%2FMod14DataXfer.pdf&usg=AOvVaw3BIkpPbpyqs_hPKd0_-PBi)\n",
        "- **drop_last**: definira sto će se dogoditi s posljednjim batchem ukoliko ukupan broj instanci dataset-a nije djeljiv s batch_size parametrom. *True* će odbaciti zadnji batch iz kalkulacija, dok će *false* uzeti zadnji batch koji će naravno biti manje veličine od batch_size parametra\n",
        "- **collate_fn**: custom funkcija koja spaja instance unutar batch-a sa specificiranom veličinom u jedan tensor. Ukoliko ne specificiramo vlastitu metodu Dataloader će po defualtu spojiti instance dataset-a u formatu niza. `_video_collate_fn()` je primjer custom metode koju koristimo prilikom testiranja te je objašnjena u nastavku.\n",
        "\n",
        "Instanca Dataloadera je iterator koji prolazi kroz sve podatke te u svakoj iteraciji vraća broj instanci dataset-a specificiran u batch_size parametru unutar jednog tenzora."
      ],
      "metadata": {
        "id": "zTmG-p_Rz8zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### _video_collate_fn()"
      ],
      "metadata": {
        "id": "oY7Z5-3aWqS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uloga ove funkcije jest spajanje videa koji se nalaze u trenutnom batchu iteracije dataloadera. \n",
        "\n",
        "Svaka instanca dataset-a se dohvaća u formatu [channels, frame, height , width] specificiranom unutar **\\_\\_getitem()\\_\\_ metode. "
      ],
      "metadata": {
        "id": "4x_u-2Z0W_l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _video_collate_fn(x):\n",
        "    \"\"\"Collate function for Pytorch dataloader to merge multiple videos.\n",
        "\n",
        "    This function should be used in a dataloader for a dataset that returns\n",
        "    a video as the first element, along with some (non-zero) tuple of\n",
        "    targets. Then, the input x is a list of tuples:\n",
        "      - x[i][0] is the i-th video in the batch\n",
        "      - x[i][1] are the targets for the i-th video\n",
        "\n",
        "    This function returns a 3-tuple:\n",
        "      - The first element is the videos concatenated along the frames\n",
        "        dimension. This is done so that videos of different lengths can be\n",
        "        processed together (tensors cannot be \"jagged\", so we cannot have\n",
        "        a dimension for video, and another for frames).\n",
        "      - The second element is contains the targets with no modification.\n",
        "      - The third element is a list of the lengths of the videos in frames.\n",
        "    \"\"\"\n",
        "    video, target = zip(*x)  # Extract the videos and targets\n",
        "\n",
        "    # ``video'' is a tuple of length ``batch_size''\n",
        "    #   Each element has shape (channels=3, frames, height, width)\n",
        "    #   height and width are expected to be the same across videos, but\n",
        "    #   frames can be different.\n",
        "\n",
        "    # ``target'' is also a tuple of length ``batch_size''\n",
        "    # Each element is a tuple of the targets for the item.\n",
        "\n",
        "    i = list(map(lambda t: t.shape[1], video))  # Extract lengths of videos in frames\n",
        "\n",
        "    # This contatenates the videos along the the frames dimension (basically\n",
        "    # playing the videos one after another). The frames dimension is then\n",
        "    # moved to be first.\n",
        "    # Resulting shape is (total frames, channels=3, height, width)\n",
        "    video = torch.as_tensor(np.swapaxes(np.concatenate(video, 1), 0, 1))#zamijeni prvu(channels) i drugu(frames) os tako da rezultat bude [frame, channel, h, w]\n",
        "\n",
        "    # Swap dimensions (approximately a transpose)\n",
        "    # Before: target[i][j] is the j-th target of element i\n",
        "    # After:  target[i][j] is the i-th target of element j\n",
        "    target = zip(*target)\n",
        "\n",
        "    return video, target, i"
      ],
      "metadata": {
        "id": "bgGWSot9W2U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Dataset\n",
        "PyTorch podržava 2 različita tipa/formata datasetova koji se razlikuju po načinu pristupanja:\n",
        "1. **map-style** datasets\n",
        "2. **iterable-style** datasets\n",
        "\n",
        "Za potrebe ovog projekta korišten je **map-style dataset** koji implementira **\\_\\_getitem\\_\\_**() i **\\_\\_len\\_\\_**() metode koje definiraju protokol pristupanja instancama sličan key-value pristupima unutar objekata ili hash mapa. \n",
        "\n",
        "Budući da je srž projekta segmentacija, kako bi imali dataset koji je kompatibilan s **Torchvision** metodama i modelom za segmentaciju potrebno je slijediti pravila programskog okvira koja nalažu da naš dataset moramo definirati kroz sučelje **torchvision.datasets.VisionDataset** klase. \n",
        "\n",
        "Ukoliko želimo koristiti vlastiti dataset(a ne neki javno dostupni i ugrađen u programski okvri) tada se procedura sastoji od nasljeđivanja **torchvision.datasets.VisionDataset** klase i definiranja vlastitog konstruktora(**\\_\\_init\\_\\_** metoda) te vlastitih **\\_\\_getitem\\_\\_**() i **\\_\\_len\\_\\_**() metoda.\n",
        "\n",
        "Upravo je to sadržaj **echo.py** datoteke čije ćemo dijelove objasniti u nastavku."
      ],
      "metadata": {
        "id": "oYByKY-t0AmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### \\_\\_init\\_\\_()"
      ],
      "metadata": {
        "id": "0sSh5FjRNXv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sukladno objektno-orijentiranoj paradigmi, funkcija konstruktora se automatski poziva prilikom kreiranja instance zadane klase(u našem slučaju je to instanca dataset-a). \n",
        "\n",
        "Prilikom kreiranja instance dataset-a u konstruktoru postavljamo određene parametre koji se tiču cjelokupnog dataset-a. Parametri se proslijeđuju kao argumenti konstruktora prilikom kreiranja instance te su navedeni u nastavku:\n",
        "- root (string): Root direktorij u kojem se nalazi dataset (default `echonet.config.DATA_DIR`)\n",
        "- split (string): Definira filter koji određuje koje instance dataset-a uzimamo u obzir ovisno o situaciji. To je ujedno i naziv stupca/labele u `FileList.csv` tablici koji omogućuje zadano filtriranje.  Moguće vrijendosti su:\n",
        "  - `train`(koriste se prilikom treniranja modela)\n",
        "  -  `val`(koriste se prilikom validacije modela)\n",
        "  - `test`(koriste se prilikom testiranja modela)\n",
        "  - `all`(uzmi sve podatke neovisno o labeli)\n",
        "  - `external_test`(uzmi eksterne podatke koji se nalaze na lokaciji specificiranoj u `external_test_location`\n",
        "- target_type (string or list, optional): parametar koji definira koje atribute od svih dostupnih ćemo uzeti u obzir za svaku instancu dataset-a. Svi mogući atributi su:\n",
        "  - `Filename`: ime video datoteke\n",
        "  - `EF(ejection-fraction)`: postotak volumena u odnosu na EDV koji srce potisne prilikom kontrakcije\n",
        "  - `EDV(end-diastolic volume)`: volumen srca u trenutku dijastole, najveći volumen prilikom ciklusa\n",
        "  - `ESV(end-systolic volume)`: volumen srca u trenutku sistole, najmanji volumen prilikom ciklusa\n",
        "  - `LargeIndex`: indeks frame-a videa u kojem se događa EDV\n",
        "  - `SmallIndex`: indeks frame-a videa u kojem se događa ESV\n",
        "  - `LargeFrame`: matrica frame-a videa u kojem se događa EDV s normaliziranim vrijednostima u intervalu [0-1]\n",
        "  - `SmallFrame`: matrica frame-a videa u kojem se događa ESV s normaliziranim vrijednostima u intervalu [0-1] \n",
        "  - `LargeTrace`: segmentacijska matrica `LargeFrame-a` u kojoj su pikseli koji su unutar lijeve komore/klijetke u EDV trenutku označeni s 1, a oni koji su izvan s 0\n",
        "  - `SmallTrace`: segmentacijska matrica `SmallFrame-a` u kojoj su pikseli koji su unutar lijeve komore/klijetke u ESV trenutku označeni s 1, a oni koji su izvan s 0\n",
        "- mean(int, float, or np.array shape=(3,), optional): aritmetička sredina za sve R,G,B kanale zajedno ili za svaki kanal odvojeno. Bitna kod normalizacije piksela videa.\n",
        "-std (int, float, or np.array shape=(3,), optional): standardna devijacija za sve R,G,B kanale zajedno ili za svaki kanal odvojeno. Bitna kod normalizacije piksela videa.\n",
        "- length (int or None, optional): ukupan točan broj frame-ova koje ćemo izvući iz videa. Ako je None uzimamo koliko je dopušteno s `max_length` parametrom.\n",
        "- period (int, optional): definira frameove koje ćemo ekstrahirati iz videa. Npr, ukoliko je period=2 ekstrahirat će se frameovi 1, 3, 5, ...\n",
        "- max_length (int or None, optional): definira maksimalni broj frame-ova koje ćemo uzeti iz videa. Ako je None nema ograničenja.\n",
        "- clips (int, optional): broj mini-videa koje ćemo uzorkovati unutar glavnog videa koji poštuju `length`, `max_length` i `period` vrijednosti. Default 1.\n",
        "- pad (int or None, optional): broj piksela koje je potrebno nadodati sa svake strane frame-a prilikom proširenja rezolucije. U tom slučaju u sredini će biti početni frame-ovi dok će rubovi biti obojani \"srednjom\" bojom frame-a(normalizirana vrijednost 0). \n",
        "- noise (float or None, optional): postotak piksela kod kojih ćemo dodati/uzrokovati šum radi poboljšanja robusnosti modela i smanjenja potencijalnog overfittinga.\n",
        "- target_transform (callable, optional): metoda koja prima sliku i labele te ih transformira na način zadan u metodi.\n",
        "- external_test_location (string): lokacija eksternih podatka za testiranje ukoliko je `split` postavljen na `external_test`\n",
        "\n",
        "Također, sukladno objektno-orijentiranoj paradigmi prilikom nasljeđivanja parent klase potrebno je u child klasi pozvati konstruktor parent klase(u našem slučaju **torchvision.datasets.VisionDataset**). Klasi se proslijeđuju `root` i `target_transform` parametri sukladno specifikaciji **PyTorcha**.\n",
        "\n",
        "Pristup instanci objekta klase za kojeg se poziva konsturktor u Pythonu je omogućen kroz **self** varijablu definiranu od strane Python okruženja i postavljene kao prvi parametar konstruktora.\n",
        "\n",
        "Inicijalizacija parametara koji se tiču cijelog dataset-a zajedno s predefiniranim vrijednostima parametara konsturuktora i pozivom parent klase prikazan je u sljedećem isječku."
      ],
      "metadata": {
        "id": "Y2yOA57Rgtt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def __init__(self, root=None,\n",
        "                 split=\"train\", target_type=\"EF\",\n",
        "                 mean=0., std=1.,\n",
        "                 length=16, period=2,\n",
        "                 max_length=250,\n",
        "                 clips=1,\n",
        "                 pad=None,\n",
        "                 noise=None,\n",
        "                 target_transform=None,\n",
        "                 external_test_location=None):\n",
        "        if root is None:\n",
        "            root = echonet.config.DATA_DIR\n",
        "\n",
        "        super().__init__(root, target_transform=target_transform)\n",
        "\n",
        "        self.split = split.upper()\n",
        "        if not isinstance(target_type, list):\n",
        "            target_type = [target_type]\n",
        "        self.target_type = target_type\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.length = length\n",
        "        self.max_length = max_length\n",
        "        self.period = period\n",
        "        self.clips = clips\n",
        "        self.pad = pad\n",
        "        self.noise = noise\n",
        "        self.target_transform = target_transform\n",
        "        self.external_test_location = external_test_location"
      ],
      "metadata": {
        "id": "LBOpmKvmia9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nakon inicijalizacije svih parametara prvi korak je učitavanje podataka vezanih za instance dataset-a koje ćemo koristiti. Podaci su pohranjeni u 2 osnovne datoteke:\n",
        "- FileList.csv\n",
        "- VolumeTracings.csv\n",
        "\n",
        "Prvo ćemo dohvatit podatke iz FileList.csv datoteke korištenjem `pandas.read_csv()` metode koja nam omogućuje manipulaciju sa .csv datotekama. `header` atribut će se postaviti na listu imena stupaca tablice, dok će `value` atribut biti niz koji će kao članove sadržavati vrijednosti redaka tablice za svaki video također u obliku niza. Također, moguće je specificiranjem imena stupca dobiti sve vrijednosti tog stupca korištenjem `x[ime_stupca]` sintakse.\n",
        "\n",
        "`header` vrijednost ćemo spremiti u `self.header` varijablu, `value` u `self.outcome` te ćemo u `self.fnames` pohraniti imena svih datoteka koje sadrže videa."
      ],
      "metadata": {
        "id": "H-98YTNMF8C7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        self.fnames, self.outcome = [], []\n",
        "\n",
        "        if self.split == \"EXTERNAL_TEST\":\n",
        "            self.fnames = sorted(os.listdir(self.external_test_location))\n",
        "        else:\n",
        "            # Učitaj \"FileList.csv\" datoteku\n",
        "            with open(os.path.join(self.root, \"FileList.csv\")) as f:\n",
        "                data = pandas.read_csv(f)\n",
        "            # Osiguraj da su sve vrijednosti \"Split\" stupca napisane velikim slovima\n",
        "            data[\"Split\"].map(lambda x: x.upper())\n",
        "\n",
        "            if self.split != \"ALL\":\n",
        "                # Uzmi samo one datoteke/videa koji imaju vrijednost \"Split\" atributa jednaku onoj proslijeđenoj u konstruktor\n",
        "                data = data[data[\"Split\"] == self.split]\n",
        "                # U suprotnome uzmi sve datoteke/videa\n",
        "\n",
        "            # Imena stupaca tablice\n",
        "            self.header = data.columns.tolist()\n",
        "            # Imena svih datoteka/videa tablice\n",
        "            self.fnames = data[\"FileName\"].tolist()\n",
        "            # Ukoliko ime nema ekstenziju po defaultu postavi da je riječ o avi formatu\n",
        "            self.fnames = [fn + \".avi\" for fn in self.fnames if os.path.splitext(fn)[1] == \"\"]\n",
        "            # Tenzor koji sadržava vrijednosti atributa tablice svih redaka\n",
        "            self.outcome = data.values.tolist()\n",
        "\n",
        "            # Broj redaka tablice(videa) mora biti jednak broju dostupnih videa odnosno svi videi koji se javljaju u tablici moraju biti dostupni\n",
        "            # Kako provjeriti? \n",
        "            # Duljina self.fnames mora biti jednaka broju datoteka videa u direktoriju\n",
        "            # Python -> razlika set()-ova jednaka je razlici broja elemenata set()-ova\n",
        "            missing = set(self.fnames) - set(os.listdir(os.path.join(self.root, \"Videos\")))\n",
        "            if len(missing) != 0:\n",
        "                print(\"{} videos could not be found in {}:\".format(len(missing), os.path.join(self.root, \"Videos\")))\n",
        "                for f in sorted(missing):\n",
        "                    print(\"\\t\", f)\n",
        "                raise FileNotFoundError(os.path.join(self.root, \"Videos\", sorted(missing)[0]))"
      ],
      "metadata": {
        "id": "g0_IUSdMGKS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time smo učitali sve podatke vezane uz Filelist.csv datoteku.\n",
        "\n",
        "Značenja atributa tablice iz VolumeTracings.csv datoteke nisu intuitivna za razliku od onih iz Filelist.csv datoteke te su usko vezani uz problematiku koju pokušavamo rješiti u našem slučaju.\n",
        "\n",
        "**[STAVI OVDE PRVU SLIKU FILE-A]**\n",
        "\n",
        "Prisjetimo se, naš cilj je segmentirati lijevu komoru/klijetku srca na videozapisu. Kako bi naš model mogao \"naučiti\" razlikovati lijevu klijetku od ostatka srca mi ga moramo istrenirati na način da mu na velikom broju slika označimo gdje se nalazi lijeva klijetka. Upravo je to uloga VolumeTracings.csv datoteke.\n",
        "\n",
        "Međutim, preostaje jedno važno pitanje: Kako računalu na efektivan način predstaviti gdje se na slici/frameu nalazi lijeva komora/klijetka?\n",
        "\n",
        "Neki početni *bruteforce* odgovor bi bio da svakoj slici pridružimo bitmapu koja će s 1 označiti pixele koji predstavljaju lijevu komoru a s 0 ostale piksele. Lako je zaključiti da je ovakav pristup iznimno neefikasan kako memorijski tako i vremenski za labeliranje podataka.\n",
        "\n",
        "U ovom projektu je stoga korištena kreativna ideja u vidu predstavljanja lijeve komore/klijetke dužinama kao što je prikazano na idućoj slici:\n",
        "\n",
        "**[STAVI OVDE DRUGU SLIKU IZ ČLANKA]**\n",
        "\n",
        "Svaka dužina definirana je s 2 točke od kojih svaka ima vlastitu x i y koordinatu unutar koordinatnog sustava slike. Ukoliko povežemo točke dužina ravnim linijama dobit ćemo poligon koji omeđuje lijevu komoru/klijetku srca te ćemo njenu poziciju na slici moći predočiti računalu. \n",
        "\n",
        "VolumeTracings.csv datoteka sadrži koordinate prve(X1,Y1) i druge(X2,Y2) točke dužina grupiranih po imenu videa definiranog u \"FileName\" stupcu i frame-u čiji je redni broj definiran u \"Frame\" stupcu. \n",
        "\n",
        "Način označavanja lijeve komore/klijetke na slici će biti detaljnjije obrađen kasnije. \n",
        "\n",
        "Podatke iz VolumeTracings.csv datoteke ćemo spremati u **self.frames** i **self.trace** atribute koji će biti **collections.defaultdict** Python [tipa](https://www.geeksforgeeks.org/defaultdict-in-python/) koji radi na key-value principu."
      ],
      "metadata": {
        "id": "vCCawydQMXo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "self.frames = collections.defaultdict(list)\n",
        "self.trace = collections.defaultdict(_defaultdict_of_lists)\n",
        "\n",
        "def _defaultdict_of_lists():\n",
        "    return collections.defaultdict(list)"
      ],
      "metadata": {
        "id": "gmTARqLBTSCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vidimo da će **self.frames** za value dio sadržavati listu, dok će **self.trace** za value dio sadržavati drugi dictionary koji će zatim za svoj value dio sadržavati listu.Ove razine indeksiranja bit će jasnije kada objasnimo značenje ovih atributa.\n",
        "\n",
        "Uloga **self.frames** atributa je da za svaku datoteku/video za koji imamo podatak u VolumeTracings.csv datoteci zapišemo listu rednih brojeva frame-ova za koje su definirani podaci. Key će biti ime datoteke dok će value biti lista indeksa frame-ova.\n",
        "\n",
        "Uloga **self.trace** atributa je da za svaku datoteku/video za koji imamo podatak u VolumeTracings.csv datoteci za svaki njegov frame zapišemo listu u kojoj će svaki član biti niz od 4 člana koji predstavljaju x1, y1, x2, y2 koordinate točaka dužine. Svi članovi liste za zadani frame predstavljaju potpuni prikaz/oznaku lijeve komore/klijetke srca na zadanom frame-u.\n",
        "\n",
        "Programski kod za inicijalizaciju ovih atributa je sljedeći:\n",
        "\n"
      ],
      "metadata": {
        "id": "SPwbMVaHTlfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "             with open(os.path.join(self.root, \"VolumeTracings.csv\")) as f:\n",
        "                header = f.readline().strip().split(\",\")\n",
        "                assert header == [\"FileName\", \"X1\", \"Y1\", \"X2\", \"Y2\", \"Frame\"]\n",
        "                for line in f:\n",
        "                    # line = redak tablice, vrijednosti retka su odvojene zarezom pa ih parsiramo prema tom formatu\n",
        "                    filename, x1, y1, x2, y2, frame = line.strip().split(',')\n",
        "                    x1 = float(x1)\n",
        "                    y1 = float(y1)\n",
        "                    x2 = float(x2)\n",
        "                    y2 = float(y2)\n",
        "                    frame = int(frame)\n",
        "                    if frame not in self.trace[filename]:\n",
        "                        # Dodaj redni broj frame-a u za zadani file za kojeg imamo podatke\n",
        "                        self.frames[filename].append(frame)\n",
        "                    # Dodaj koordinate dužine za zadani file i zadani frame u formatu Python liste\n",
        "                    self.trace[filename][frame].append((x1, y1, x2, y2))\n",
        "            for filename in self.frames:\n",
        "                for frame in self.frames[filename]:\n",
        "                    #Pretvori iz tliste u NumPy niz\n",
        "                    self.trace[filename][frame] = np.array(self.trace[filename][frame])\n",
        "\n",
        "            # Zadrzi podatke samo za ona videa koji imaju podatke u VolumeTracings.csv datoteci\n",
        "            # U slucaju da neki videi nemaju zadane tracing podatke\n",
        "            keep = [len(self.frames[f]) >= 2 for f in self.fnames]\n",
        "            self.fnames = [f for (f, k) in zip(self.fnames, keep) if k]\n",
        "            self.outcome = [f for (f, k) in zip(self.outcome, keep) if k]"
      ],
      "metadata": {
        "id": "E01LF2jLXaVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time je završena obrada uloge i same implementacija **\\_\\_init\\_\\_()** konstruktora našeg dataset-a."
      ],
      "metadata": {
        "id": "g3zdaeqlY5kr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **\\_\\_getitem()\\_\\_**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gl33J_kaZaFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kao što je prethodno rečeno, u našem projektu koristimo **map-style** dataset u kojem podacima pristupa preko key-value mehanizma. Prilikom učitavanja svake instance dataset-a **PyTorch** će pozvati ovu metodu za svaku instancu te joj automatski proslijediti `index` parametar u metodu koji označava index(redni broj-1) videa unutar direktorija iz kojeg se učitavaju podaci.\n",
        "\n",
        "Prvi korak u metodi je učitavanje videa specificiranog zadanim indeksom. Budući da je redoslijed videa u direktoriju jednak redoslijedu redaka u FileList.csv datoteci možemo koristit **self.fnames** listu definiranu unutar konstruktora koja će nam za zadani `index` vratiti ime datoteke/videa koje nam je potrebno za njegovo učitavanje. Učitavanje videa ćemo raditi korištenjem `loadvideo()` utility funkcije."
      ],
      "metadata": {
        "id": "t-NoiPQ6ZwEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nakon poziva `loadvideo()` metode imamo tenzor koji sadrži podatke o R,G,B vrijednostima za svaki frame i svaki piksel na frame-u i to u [channel, frame, height, width] formatu."
      ],
      "metadata": {
        "id": "oReyWrFsq1N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def __getitem__(self, index):\n",
        "        #index= INDEX videa u direktoriju odakle se dohvaćaju podaci\n",
        "        # Find filename of video\n",
        "        if self.split == \"EXTERNAL_TEST\":\n",
        "            video = os.path.join(self.external_test_location, self.fnames[index])\n",
        "        elif self.split == \"CLINICAL_TEST\":\n",
        "            video = os.path.join(self.root, \"ProcessedStrainStudyA4c\", self.fnames[index])\n",
        "        else:\n",
        "            video = os.path.join(self.root, \"Videos\", self.fnames[index])\n",
        "\n",
        "        # Load video into np.array\n",
        "        #format c,f,h,w\n",
        "        video = echonet.utils.loadvideo(video).astype(np.float32)"
      ],
      "metadata": {
        "id": "Bmg3hpRrvq9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Idući korak je provjera potrebe za ubacivanjem šuma u učitane podatke ukoliko je to bilo definirano s **noise** parametrom konstruktora koji definira postotak piksela na kojima će biti kreiran šum.. \n",
        "\n",
        "Šum se sastoji u postavljanju crne boje odnosno vrijednosti 0 za R,G,B vrijednosti budući da vrijednosti boja još nisu normalizirane u ovom trenutku.\n",
        "\n",
        "Budući da **noise** parametar predstavlja postotak piksela u videu kod kojih ćemo postaviti šum prvo moramo izračunati ukupan broj piksela videa koji se dobije prema formuli:\n",
        "\n",
        "\n",
        "```\n",
        "broj_pixela = broj_frameova * broj_redaka * broj_stupaca\n",
        "```\n",
        "\n",
        "Od ukupnog broja pixela u njih `self.noise * broj_pixela` će biti umetnut šum. Budući da je i ideja samog šuma u random smetnji tada ćemo na slučajan/random način izabrati `self.noise * broj_pixela` indeksa u rasponu od 0 do `broj_pixela`.\n",
        "\n",
        "Nakon odabira indeksa budući da je naš video objekt u formatu [channel, frame, height, width] moramo se vratiti u njegovu indeksaciju odnosno iz odabranog indeksa dobiti informaciju o kojem je frame-u riječ i o kojim je x,y koordinatama piksela unutar frame-a riječ.\n",
        "\n"
      ],
      "metadata": {
        "id": "BvAobnQZrTSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "          if self.noise is not None:\n",
        "            # Ukupan broj pixela u cijelom videu\n",
        "            n = video.shape[1] * video.shape[2] * video.shape[3]\n",
        "            # Odaberi na random način indekse piksela u koje ćemo unijeti šum\n",
        "            # Biramo self.noise * n indeksa u rasponu 0- n\n",
        "            ind = np.random.choice(n, round(self.noise * n), replace=False)\n",
        "            # Vrati se u [c,f,h,w] indeksaciju\n",
        "            f = ind % video.shape[1]\n",
        "            ind //= video.shape[1]\n",
        "            i = ind % video.shape[2]\n",
        "            ind //= video.shape[2]\n",
        "            j = ind\n",
        "            # Postavi R,G,B vrijednosti na 0 -> crna boja = šum\n",
        "            video[:, f, i, j] = 0"
      ],
      "metadata": {
        "id": "tk6HGzZ-v4X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nakon opcionalnog ubacivanja šumova slijedi obvezna normalizacija R,G,B vrijednosti na raspon [0-1] i to korištenjem formule za jediničnu normalnu varijablu z:\n",
        "\n",
        "\n",
        "```\n",
        "z = (x - μ) / σ\n",
        "```\n",
        "\n",
        "Uočavamo da su za normalizaciju potrebne prethodno izračunate artmetička sredina i standardna devijacija izračunate posebno za svaki kanal i proslijeđene u konstruktor. Kako bi mogli dijeliti video tenzor [channel, frame, height, width] formata po svakom kanalu s odgovarajućom aritmetičkom sredinom i standardnom devijacijom za zadani kanal potrebno je pretvoriti aritmetičku sredinu i standardnu devijaciju u tenzore dimenzija [3, 1, 1 ,1]\n",
        "\n"
      ],
      "metadata": {
        "id": "GTjTsG7kwzR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        if isinstance(self.mean, (float, int)):\n",
        "            video -= self.mean\n",
        "        else:\n",
        "            video -= self.mean.reshape(3, 1, 1, 1)\n",
        "\n",
        "        if isinstance(self.std, (float, int)):\n",
        "            video /= self.std\n",
        "        else:\n",
        "            video /= self.std.reshape(3, 1, 1, 1)"
      ],
      "metadata": {
        "id": "OMreCLSByrAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sljedeći korak je osiguravanje kriterija postavljenih s `length`, `max_length` i `period` parametrima konstruktora. \n",
        "\n",
        "Prisjetimo se da `length` definira točan broj frame-ova koje će sadržavati video(ukoliko je specificiran, u suprotnome uzimamo sve frame-ove koje možemo) dok `max_length` definira maksimalan broj frame-ova koje video može sadržavati. \n",
        "\n",
        "Broj frame-ova koje ćemo uzeti u razmatranje ovisi o `period` parametru koji definira period uzorkovanja frame-ova videa. Npr. ukoliko naš video ima 20 frame-ova a uzorkujemo svaki drugi frame tada će rezultantni video imati 20 / 2 = 10 frame-ova. \n",
        "\n",
        "Također, potrebno je osigurati da veličina krajnjeg rezultatnog videa bude manja od `max_length` vrijednosti, ali u isto vrijeme i barem jednaka `length` vrijednosti ukoliko je ona specificirana.\n",
        "\n",
        "Ukoliko je veća od `max_length` uzimamo samo prvih `max_length` frame-ova.\n",
        "\n",
        "Ukoliko je manja od `length` *paddamo* video na njegovom kraju na način da frame-ove koji nedostaju dodamo na kraj videa te njihove R,G,B vrijdnosti postavimo u 0.\n",
        "> Napomena: za razliku od umetanja šuma u ovom trenutku R,G,B vrijednosti su normalizirane pa vrijendost 0 predstavlja vrijednost aritmeticke sredine izvornih R,G,B boja."
      ],
      "metadata": {
        "id": "MLKfLEHF2qEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        c, f, h, w = video.shape\n",
        "        if self.length is None:\n",
        "            # length označava broj frame-ova uzorkovanog videa\n",
        "            length = f // self.period\n",
        "        else:\n",
        "            # Rezultantni video mora imati točno length frame-ova\n",
        "            length = self.length\n",
        "\n",
        "        if self.max_length is not None:\n",
        "            # Uzmi prvih max_length frame-ova ako je length > max_length\n",
        "            length = min(length, self.max_length)\n",
        "\n",
        "        #Broj frameova rezultantog videa manji od broja frameova specificranog u length(za slučaj None uvijek prolazi)\n",
        "        if f < length * self.period:\n",
        "            # Paddamo video s frame-ovima pri kraju i to za onoliko frame-ova koliko nam nedostaje do željene duljine\n",
        "            video = np.concatenate((video, np.zeros((c, length * self.period - f, h, w), video.dtype)), axis=1)\n",
        "            c, f, h, w = video.shape  # pylint: disable=E0633"
      ],
      "metadata": {
        "id": "3FxZnSyW2x34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sljedeći dio koda je vezan uz uzorkovanje i dijeljenje videa u manje dijelove tzv. clipove. Ova značajka može biti korisna za povećanje broja instanci na način da iz jednog videa dobijemo veći broj manjih videa i time umjetno povećamo broj videa na način da unutar jednog video objekta imamo više zasebnih clipova. Ovo može biti korisno prilikom testiranja modela jer tada izvodimo predikcije na odabranih tipovima podataka, a ovim postupkom povećavamo veličinu testnog seta.\n",
        "\n",
        "Ukoliko je parametar postavljen na ključnu riječ \"all\" tada uzimamo sve moguće clipove unutar videa. Npr. svi mogući clipovi duljine 5 frame-ova unutar videa duljine 10 frame-ova bi bili [1,2,3,4,5], [2,3,4,5,6], ... Zaključujemo da se samo shiftamo za jedan frame udesno. Krajnja granica do koje se možemo shiftati je onaj frame nakon kojeg postoji još `length` frame-ova do kraja videa odnosno:\n",
        "\n",
        "\n",
        "```\n",
        "zadnji_indeks = broj_frameova - (length - 1) * period_uzorkovanja\n",
        "```\n",
        "što je upravo i definirano u kodu.\n",
        "\n",
        "Ukoliko je **self.clips** postavljen na broj tada iz videa želimo izvući **self.clips** clipova duljine `length`. Logika uvjeta za zadnji indeks je ista samo što za razliku od \"all\" slučaja ne uzimamo sve indekse u rasponu od [0 - zadnji_indeks] već na random način u tom rasponu biramo **self.clips** početnih indeksa. Ukoliko je **self.cips** postavljen na 1 te uzorkujemo cijeli video(`length = None`) tada će rezultat biti cijeli video uzorkovan specificiranom sample frekvencijom.\n",
        "\n",
        "Odabrane indekse početaka clipov spremamo u start niz.\n",
        "\n"
      ],
      "metadata": {
        "id": "fDItcoAL8x1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        if self.clips == \"all\":\n",
        "            start = np.arange(f - (length - 1) * self.period)\n",
        "        else:\n",
        "            start = np.random.choice(f - (length - 1) * self.period, self.clips)"
      ],
      "metadata": {
        "id": "lBOe9LUg8yQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prilikom definiranja argumenata konstruktora spomenuli smo `target_type` parametar koji definira atribute koje ćemo pridružiti svakoj instanci dataset-a/videu. Mogući atributi su prethodno navedeni prilikom definiranja parametara konstruktora, a u nastavku su prikazani načini njihove inicijalizacije:\n",
        "\n",
        "- Filename: možemo ga lako dohvatiti iz **self.fnames** preko `indexa` koji se proslijeđuje **\\_\\_getitem\\_\\_** metodi\n",
        "- LargeIndex: za svaki video imamo pohranjene indekse svih frame-ova koji imaju podatke u VolumeTracings.csv datoteci u **self.frames**. Budući da je riječ o dijastoli, podaci za dijastolu će u tablici uvijek biti posljednje navedeni pa uzimamo zadnji član **self.frames** niza za video određen `indexom`.\n",
        "- SmallIndex: ista logika kao za `LargeIndex` samo što su u ovom slučaju podaci za sistolu navedeni odmah na početku pa uzimamo zadnji član **self.frames** niza za video određen `indexom`.\n",
        "- LargeFrame: podaci za frame na `LargeIndex` poziciji. Budući da smo dohvatili video u [channel, frame, height, width] formatu za dohvat podataka potrebno je samo specificirati indeks frame-a, a on je identičan `LargeIndex`\n",
        "- SmallFrame: podaci za frame na `SmallIndex` poziciji. Budući da smo dohvatili video u [channel, frame, height, width] formatu za dohvat podataka potrebno je samo specificirati indeks frame-a, a on je identičan `SmallIndex`\n",
        "- LargeTrace i SmallTrace: želimo dohvatiti podatke iz VolumeTracings.csv datoteke za frame definiran s `LargeIndex/SmallIndex`. Prethodno smo u konstruktoru pohranili VolumeTracings.csv podatke u **self.trace** dictionary grupirane po imenu videa i indeksu frame-a pri čemu su podaci pohranjeni u obliku liste 4-članih nizova (x1, y1, x2, y2). U našem slučaju imamo definirano ime videa kroz `index` parametar te znamo indeks frame-a preko `LargeIndex/SmallIndex` varijable pa stoga možemo na jednostavan način dohvatiti podatke o dužinama za zadani frame. \n",
        "\n",
        "Ovdje ćemo se još malo zadržati na `LargeTrace` i `SmallTrace` targetima. Naime, predstavljanje lijeve komore/klijetke korištenjem dužina je iznimno domišljato i efektivno rješenje prilikom definiranja dataset-a. Međutim, računalo će na koncu raditi s pikselima slike te ga moramo istrenirati kako bi na zadanom frame-u uočilo i segmentiralo lijevu komoru/klijetku srca. \n",
        "\n",
        "Osnova svakog treniranja modela jest postavljanje inputa u neuralnu mrežu te usporedba rezultata/izlaza mreže s očekivanim rezultatima. Na osnovu izlazne greške model ažurira svoje težine preko tzv. *backpropagation* postupka  s ciljem smanjivanja greške uz uvijek prisutni potencijalni rizik od *overfitta*. \n",
        "\n",
        "Izlaz segmentacijskog modela u našem slučaju će biti bitovna matrica svakog frame-a u kojoj će vrijednost 1 imati pikseli za koje model smatra da predstavljaju lijevu komoru/klijetku a ostali pikseli će biti 0. \n",
        "\n",
        "Kako bi mogli na efektivan način usporediti izlaze modela sa željenim izlazima koji su opisani preko modela dužina u VolumeTracings.csv datoteci potrebno je zadani model dužina također pretočiti u prikaz bitovne matrice.\n",
        "\n",
        "Spajanjem točaka dužina ravnim linijama dobit ćemo poligon koji predstavlja lijevu komoru/klijetku. \n",
        "\n",
        "[STAVI SLIKU KO IZ ČLANKA DI SPAJAŠ TOČKE DUŽINA]\n",
        "\n",
        "Niz 4-članih nizova formata [x1, y1, x2, y2] pretvorimo u 4 zasebna niza od kojih će svi biti jednake dužine te će zasebno predstavljati x1, y1, x2, i y2 koordinate. \n",
        "\n",
        "Bitan faktor u našem postupku povezivanja točaka dužina jest svojstvo dataset-a koji je definiran na način da su točke u VolumeTracings.csv datoteci sortirane uzlazno po Y1 parametru. \n",
        "\n",
        "Budući da je ishodište koordinatnog sustava slike u **gornjem lijevom kutu** zaključujemo da su točke (x1,y1) točke koje definiraju lijevi dio komore dok su točke (x2,y2) točke koje definiraju desnu stranu komore pri čemu Y2 < Y1 zbog čega su dužine nagnute kako je prikazano na prethodnoj slici. Točke (x1,y1) su sortirane uzlazno po Y1 parametru što znači da su navedene od vrha prema dnu slike. \n",
        "\n",
        "Također, prve 2 točke (x1,y1) i (x2,y2) označavaju glavnu središnju liniju(vidljivu na slici) koja nam prilikom iscrtavanja poligona nije bitna pa stoga nećemo uzeti u obzir koordinate tih točaka.\n",
        "\n",
        "Krenemo s iscrtavanjem od prve/najgornje točke (x1,y1) te povezujemo sve (x1,y1) točke s lijeve strane komore. \n",
        "\n",
        "Nakon što smo došli do zadnje točke potrebno je nastaviti s povezivanjem (x2,y2) točaka na desnoj strani komore.\n",
        "\n",
        "Međutim, naši nizovi X1, Y1, X2, Y2 su definirani prema redoslijedu sparivanja (x1,y1) i (x2,y2) dužina odnosno prvi član X2 i Y2 niza odgovaraju točki dužine koja počinje s najgornjom točkom (x1,y1). \n",
        "\n",
        "Nakon iscrtavanje lijeve strane komore nalazimo se na posljednjoj/najdonjoj točki. Kako bi nastavili s povezivanjem poligona iduća točka bi trebala biti najdonja točka desne strane komore koja odgovara zadnjim članovima nizova X2 i Y2 te ćemo povezivanje nastaviti sve do najgornje točke. \n",
        "\n",
        "Stoga zaključujemo da ćemo prilikom iscrtavanja **invertirati** nizove X2 i Y2.\n",
        "\n",
        "Za iscrtavanje poligona koristit ćemo `skimage.draw.polygon` metodu koja prima nizove X i Y koordinata točaka koje se povezuju po redoslijedu nizova te dimenzije slike/matrice u čijem koordinatnom sustavu se odvija iscrtavanje. Bitna stvar ove metode je njena povratna vrijednost koja odgovara nizovima X i Y koordinata točaka koji se nalaze **unutar** iscrtanog poligona što u našem konkretnom slučaju predstavlja područje lijeve komore/klijetke.\n",
        "\n",
        "Bitmapu generiramo na način da prvo inicijaliziramo matricu veličine frame-a na vrijednosti 0 te one piksele čije je koordinate vratila `skimage.draw.polygon` metoda postavimo na 1.\n",
        "\n",
        "Programska implementacija prethodno navedenih principa je realizirana sljedećim programskim kodom:"
      ],
      "metadata": {
        "id": "oaa_gW1M3IJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        # Postavi specificirane targete\n",
        "        target = []\n",
        "        for t in self.target_type:\n",
        "            key = self.fnames[index]\n",
        "            if t == \"Filename\":\n",
        "                target.append(self.fnames[index])\n",
        "            elif t == \"LargeIndex\":\n",
        "                # Index = -1 -> posljednji član\n",
        "                target.append(np.int(self.frames[key][-1]))\n",
        "            elif t == \"SmallIndex\":\n",
        "                target.append(np.int(self.frames[key][0]))\n",
        "            elif t == \"LargeFrame\":\n",
        "                target.append(video[:, self.frames[key][-1], :, :])\n",
        "            elif t == \"SmallFrame\":\n",
        "                target.append(video[:, self.frames[key][0], :, :])\n",
        "            elif t in [\"LargeTrace\", \"SmallTrace\"]:\n",
        "                if t == \"LargeTrace\":\n",
        "                    t = self.trace[key][self.frames[key][-1]]\n",
        "                else:\n",
        "                    t = self.trace[key][self.frames[key][0]]\n",
        "                #Zasebni nizovi koordinata točaka\n",
        "                x1, y1, x2, y2 = t[:, 0], t[:, 1], t[:, 2], t[:, 3]\n",
        "                # Invertiraj x2 i y2 nizove\n",
        "                x = np.concatenate((x1[1:], np.flip(x2[1:])))\n",
        "                y = np.concatenate((y1[1:], np.flip(y2[1:])))\n",
        "                r, c = skimage.draw.polygon(np.rint(y).astype(np.int), np.rint(x).astype(np.int), (video.shape[2], video.shape[3]))\n",
        "                #Veličina maske = rezolucija videa\n",
        "                mask = np.zeros((video.shape[2], video.shape[3]), np.float32)\n",
        "                #Pixeli lijeve komore/klijetke = 1\n",
        "                mask[r, c] = 1\n",
        "                # Pohrani masku\n",
        "                target.append(mask)\n",
        "            else:\n",
        "                # Nije od prevelike važnosti u našem slučaju\n",
        "                if self.split == \"CLINICAL_TEST\" or self.split == \"EXTERNAL_TEST\":\n",
        "                    target.append(np.float32(0))\n",
        "                else:\n",
        "                    target.append(np.float32(self.outcome[index][self.header.index(t)]))\n",
        "\n",
        "        if target != []:\n",
        "            #Ukoliko je definirana target_transform metoda u konstruktoru transformiraj prethodno inicijalizirani target niz\n",
        "            target = tuple(target) if len(target) > 1 else target[0]\n",
        "            if self.target_transform is not None:\n",
        "                target = self.target_transform(target)"
      ],
      "metadata": {
        "id": "DnpQUr-cG16v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Posljednji dio **\\_\\_getitem\\_\\_** metode tiče se uzorkovanja videa odnosno njegovog dijeljenja u manje isječke/clipove te *paddanja* videa ukoliko je to definirano u pozivu konstruktora. Naime, ukoliko je video duži od točno specificirane duljine `length` ili iz jednog videa želimo uzeti više isječaka/clipova tada to možemo odraditi na više načina. \n",
        "\n",
        "Ovaj dio veže se na prethodni dio dio određivanja `start` pozicija clipova koje definiraju početne indekse frame-ova clipova.\n",
        "\n",
        "Svaki clip će imati početni frame definiran unutar `start` niza te će biti dužine `length`. Npr, ukoliko početni video ima 100 frame-ova, clip je duljine 5 frame-ova, indeks početnog frame-a je 6 a želimo uzorkovati svako drugi frame(**self.period=2**) tada će se naš clip sastojati od frame-ova s indeksima 6, 8, 10, 12, 14 unutar početnog videa.\n",
        "\n",
        "Ukoliko je broj clipova postavljen na 1(default) tada ćemo kao rezultat imati jedan clip kao vrijednost `video` varijable, a u slučaju više clipova `video` varijabla će sadržavati clipove jedan iza drugog.\n",
        "\n",
        "Ukoliko želimo povećati rezoluciju videa to možemo odraditi jednostavnim mehanizmom *paddinga* čije dimenzije određuje **self.pad** parametar. Mehanizam se sastoji od \"uokviravanja\" trenutnog frame-a s okvirom čije se normalizirane R,G,B vrijednosti postavljaju na 0(srednja vrijednost boje) dok se središnji pikseli slike postavljaju na vrijednosti trenutnog frame-a.\n",
        "\n",
        "Na kraju od proširene slike frame-a uzimamo/croppamo dio veličine početne rezolucije frame-a."
      ],
      "metadata": {
        "id": "30nTHxAOIoOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        # video = lista clipova\n",
        "        video = tuple(video[:, s + self.period * np.arange(length), :, :] for s in start)\n",
        "        if self.clips == 1:\n",
        "            #Samo 1 clip napravljen -> uzmi prvi i jedini član liste\n",
        "            video = video[0]\n",
        "        else:\n",
        "            # Spoji clipove jedan iza drugog u jedinstveni niz\n",
        "            video = np.stack(video)\n",
        "\n",
        "        if self.pad is not None:\n",
        "            # Početna rezolucija\n",
        "            c, l, h, w = video.shape\n",
        "            # Proširi rezoluciju za \"okvire\" sa svih strana frame-a\n",
        "            temp = np.zeros((c, l, h + 2 * self.pad, w + 2 * self.pad), dtype=video.dtype)\n",
        "            # Područja \"unutar okvira\" postavi na vrijednosti od frame-ova od videa\n",
        "            temp[:, :, self.pad:-self.pad, self.pad:-self.pad] = video\n",
        "            i, j = np.random.randint(0, 2 * self.pad, 2)\n",
        "            # Random croppaj dio veličine početne rezolucije videa\n",
        "            video = temp[:, :, i:(i + h), j:(j + w)]\n",
        "        # Vrati video i target u obliku Python tuple tipa\n",
        "        return video, target"
      ],
      "metadata": {
        "id": "rp2urMc2ILMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **\\_\\_len\\_\\_()**"
      ],
      "metadata": {
        "id": "7EmWQyFaz_qz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metoda koju je potrebno definirati prilikom definiranja vlastitog dataset-a u **PyTorchu**. Vraća broj instanci dataset-a. U našem slučaju su imena svih instanci pohranjeni u **self.fnames** pa je dovoljno uzeti duljinu te liste."
      ],
      "metadata": {
        "id": "_bdAgQNx0ibu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def __len__(self):\n",
        "        #broj videa=broj filenameova\n",
        "        return len(self.fnames)"
      ],
      "metadata": {
        "id": "f4cLma7yz7Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **\\_\\_extra_repr\\_\\_**"
      ],
      "metadata": {
        "id": "F77LT7yV0PBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definira dodatne informacije koje se dodaju na kraj Python **\\_\\_repr\\_\\_** stringa za zadani dataset objekt."
      ],
      "metadata": {
        "id": "UJxQz6Nc1oZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def extra_repr(self) -> str:\n",
        "        \"\"\"Additional information to add at end of __repr__.\"\"\"\n",
        "        lines = [\"Target type: {target_type}\", \"Split: {split}\"]\n",
        "        return '\\n'.join(lines).format(**self.__dict__)"
      ],
      "metadata": {
        "id": "QLucnP8c0N7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-generic-recommended\n",
        "\n",
        "!jupyter nbconvert --to pdf SegmentacijaEhokardiograma.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ22aR98FkvO",
        "outputId": "27763431-3990-41bf-98eb-73103f6f90d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n",
            "  javascript-common libcupsfilters1 libcupsimage2 libgs9 libgs9-common\n",
            "  libijs-0.35 libjbig2dec0 libjs-jquery libkpathsea6 libpotrace0 libptexenc1\n",
            "  libruby2.5 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13 lmodern\n",
            "  poppler-data preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-latex-base texlive-latex-extra\n",
            "  texlive-latex-recommended texlive-pictures texlive-plain-generic tipa\n",
            "Suggested packages:\n",
            "  fonts-noto apache2 | lighttpd | httpd poppler-utils ghostscript\n",
            "  fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum ri\n",
            "  ruby-dev bundler debhelper gv | postscript-viewer perl-tk xpdf-reader\n",
            "  | pdf-viewer texlive-fonts-recommended-doc texlive-latex-base-doc\n",
            "  python-pygments icc-profiles libfile-which-perl\n",
            "  libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n",
            "  texlive-latex-recommended-doc texlive-pstricks dot2tex prerex ruby-tcltk\n",
            "  | libtcltk-ruby texlive-pictures-doc vprerex\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n",
            "  javascript-common libcupsfilters1 libcupsimage2 libgs9 libgs9-common\n",
            "  libijs-0.35 libjbig2dec0 libjs-jquery libkpathsea6 libpotrace0 libptexenc1\n",
            "  libruby2.5 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13 lmodern\n",
            "  poppler-data preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-recommended texlive-generic-recommended\n",
            "  texlive-latex-base texlive-latex-extra texlive-latex-recommended\n",
            "  texlive-pictures texlive-plain-generic texlive-xetex tipa\n",
            "0 upgraded, 47 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 146 MB of archives.\n",
            "After this operation, 460 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lato all 2.0-2 [2,698 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 tex-common all 6.09 [33.0 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lmodern all 2.004.5-3 [4,551 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-texgyre all 20160520-1 [8,761 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.9 [18.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.16 [5,093 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.16 [2,265 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkpathsea6 amd64 2017.20170613.44572-8ubuntu0.1 [54.9 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpotrace0 amd64 1.14-2 [17.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libptexenc1 amd64 2017.20170613.44572-8ubuntu0.1 [34.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 rubygems-integration all 1.11 [4,994 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ruby2.5 amd64 2.5.1-1ubuntu1.12 [48.6 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby amd64 1:2.5.1 [5,712 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 rake all 12.3.1-1ubuntu0.1 [44.9 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-did-you-mean all 1.2.0-2 [9,700 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-minitest all 5.10.3-1 [38.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-power-assert all 0.3.0-1 [7,952 B]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-test-unit all 3.2.5-1 [61.1 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libruby2.5 amd64 2.5.1-1ubuntu1.12 [3,073 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsynctex1 amd64 2017.20170613.44572-8ubuntu0.1 [41.4 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexlua52 amd64 2017.20170613.44572-8ubuntu0.1 [91.2 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexluajit2 amd64 2017.20170613.44572-8ubuntu0.1 [230 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzzip-0-13 amd64 0.13.62-3.1ubuntu0.18.04.1 [26.0 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 lmodern all 2.004.5-3 [9,631 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 preview-latex-style all 11.91-1ubuntu1 [185 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tex-gyre all 20160520-1 [4,998 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 texlive-binaries amd64 2017.20170613.44572-8ubuntu0.1 [8,179 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-base all 2017.20180305-1 [18.7 MB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-recommended all 2017.20180305-1 [5,262 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-plain-generic all 2017.20180305-2 [23.6 MB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-generic-recommended all 2017.20180305-1 [15.9 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-base all 2017.20180305-1 [951 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-recommended all 2017.20180305-1 [14.9 MB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-pictures all 2017.20180305-1 [4,026 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-latex-extra all 2017.20180305-2 [10.6 MB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tipa all 2:1.3-20 [2,978 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-xetex all 2017.20180305-1 [10.7 MB]\n",
            "Fetched 146 MB in 11s (13.0 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 47.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 155639 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.09_all.deb ...\n",
            "Unpacking tex-common (6.09) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../04-fonts-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../05-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../06-fonts-texgyre_20160520-1_all.deb ...\n",
            "Unpacking fonts-texgyre (20160520-1) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../07-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../08-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../09-libcupsimage2_2.2.7-1ubuntu2.9_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.9) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../10-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../11-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../12-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.16_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../13-libgs9_9.26~dfsg+0-0ubuntu0.18.04.16_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../14-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../15-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libpotrace0.\n",
            "Preparing to unpack .../16-libpotrace0_1.14-2_amd64.deb ...\n",
            "Unpacking libpotrace0 (1.14-2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../17-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../18-rubygems-integration_1.11_all.deb ...\n",
            "Unpacking rubygems-integration (1.11) ...\n",
            "Selecting previously unselected package ruby2.5.\n",
            "Preparing to unpack .../19-ruby2.5_2.5.1-1ubuntu1.12_amd64.deb ...\n",
            "Unpacking ruby2.5 (2.5.1-1ubuntu1.12) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../20-ruby_1%3a2.5.1_amd64.deb ...\n",
            "Unpacking ruby (1:2.5.1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../21-rake_12.3.1-1ubuntu0.1_all.deb ...\n",
            "Unpacking rake (12.3.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-did-you-mean.\n",
            "Preparing to unpack .../22-ruby-did-you-mean_1.2.0-2_all.deb ...\n",
            "Unpacking ruby-did-you-mean (1.2.0-2) ...\n",
            "Selecting previously unselected package ruby-minitest.\n",
            "Preparing to unpack .../23-ruby-minitest_5.10.3-1_all.deb ...\n",
            "Unpacking ruby-minitest (5.10.3-1) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../24-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-power-assert.\n",
            "Preparing to unpack .../25-ruby-power-assert_0.3.0-1_all.deb ...\n",
            "Unpacking ruby-power-assert (0.3.0-1) ...\n",
            "Selecting previously unselected package ruby-test-unit.\n",
            "Preparing to unpack .../26-ruby-test-unit_3.2.5-1_all.deb ...\n",
            "Unpacking ruby-test-unit (3.2.5-1) ...\n",
            "Selecting previously unselected package libruby2.5:amd64.\n",
            "Preparing to unpack .../27-libruby2.5_2.5.1-1ubuntu1.12_amd64.deb ...\n",
            "Unpacking libruby2.5:amd64 (2.5.1-1ubuntu1.12) ...\n",
            "Selecting previously unselected package libsynctex1:amd64.\n",
            "Preparing to unpack .../28-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexlua52:amd64.\n",
            "Preparing to unpack .../29-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../30-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../31-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../32-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../33-preview-latex-style_11.91-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (11.91-1ubuntu1) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../34-t1utils_1.41-2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-2) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../35-tex-gyre_20160520-1_all.deb ...\n",
            "Unpacking tex-gyre (20160520-1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../36-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../37-texlive-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../38-texlive-fonts-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../39-texlive-plain-generic_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-plain-generic (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-generic-recommended.\n",
            "Preparing to unpack .../40-texlive-generic-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-generic-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../41-texlive-latex-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../42-texlive-latex-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../43-texlive-pictures_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-pictures (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../44-texlive-latex-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-latex-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../45-tipa_2%3a1.3-20_all.deb ...\n",
            "Unpacking tipa (2:1.3-20) ...\n",
            "Selecting previously unselected package texlive-xetex.\n",
            "Preparing to unpack .../46-texlive-xetex_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-xetex (2017.20180305-1) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up tex-gyre (20160520-1) ...\n",
            "Setting up preview-latex-style (11.91-1ubuntu1) ...\n",
            "Setting up fonts-texgyre (20160520-1) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up fonts-lato (2.0-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.9) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up ruby-did-you-mean (1.2.0-2) ...\n",
            "Setting up t1utils (1.41-2) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up rubygems-integration (1.11) ...\n",
            "Setting up libpotrace0 (1.14-2) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up ruby-minitest (5.10.3-1) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-lmodern (2.004.5-3) ...\n",
            "Setting up ruby-power-assert (0.3.0-1) ...\n",
            "Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up texlive-base (2017.20180305-1) ...\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-plain-generic (2017.20180305-2) ...\n",
            "Setting up texlive-generic-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-latex-base (2017.20180305-1) ...\n",
            "Setting up lmodern (2.004.5-3) ...\n",
            "Setting up texlive-latex-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-pictures (2017.20180305-1) ...\n",
            "Setting up tipa (2:1.3-20) ...\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-DEBIAN'... done.\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST'... done.\n",
            "update-fmtutil has updated the following file(s):\n",
            "\t/var/lib/texmf/fmtutil.cnf-DEBIAN\n",
            "\t/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST\n",
            "If you want to activate the changes in the above file(s),\n",
            "you should run fmtutil-sys or fmtutil.\n",
            "Setting up texlive-latex-extra (2017.20180305-2) ...\n",
            "Setting up texlive-xetex (2017.20180305-1) ...\n",
            "Setting up ruby2.5 (2.5.1-1ubuntu1.12) ...\n",
            "Setting up ruby (1:2.5.1) ...\n",
            "Setting up ruby-test-unit (3.2.5-1) ...\n",
            "Setting up rake (12.3.1-1ubuntu0.1) ...\n",
            "Setting up libruby2.5:amd64 (2.5.1-1ubuntu1.12) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "[NbConvertApp] Converting notebook SegmentacijaEhokardiograma.ipynb to pdf\n",
            "[NbConvertApp] Writing 466173 bytes to ./notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 300900 bytes to SegmentacijaEhokardiograma.pdf\n"
          ]
        }
      ]
    }
  ]
}